kubernetes

pip install dask-kubernetes --upgrade 

gcloud components install gke-gcloud-auth-plugin


-------------------------- Google K8 Cluster Management -----------------------------

gcloud container clusters create \
  --machine-type n1-standard-4 \
  --num-nodes 2 \
  --zone us-central1-a \
  --cluster-version latest \
  coolercluster

kubectl create clusterrolebinding cluster-admin-binding \
--clusterrole=cluster-admin \
--user=adrianbeerka


gcloud container clusters resize coolercluster --node-pool POOL_NAME \
    --num-nodes 0
  
-------------------------- Helm -------------------------------------
helm repo add dask https://helm.dask.org/
helm repo update
helm install --create-namespace -n dask-operator --generate-name dask/dask-kubernetes-operator

helm list
helm delete <>

***HelmCluster is a fixed cluster option, KubeCluster is an ephemeral one.
  
It is not possible to use HelmCluster from the Jupyter session which is deployed as part of the Helm Chart without first copying your ~/.kube/config file to that Jupyter session.

Dask and Kubernetes:
- Workers connect to the scheduler via the scheduler Service and that service can also be exposed to the user in order to connect clients and perform work.
  
  
------------- .YAML File configuration -------------------
1. kubectl apply -f - <<EOF
apiVersion: kubernetes.dask.org/v1
kind: DaskCluster
metadata:
  name: my-dask-cluster
spec:
  ...
2. cluster = KubeCluster(name="my-dask-cluster", image='ghcr.io/dask/dask:latest')

is the same as:
cluster = KubeCluster(custom_cluster_spec="cluster.yml")


------------- KubeCluster ------------------------
*** KubeCluster isn't designed to interface directly with gcloud. It is designed to be run from a pod on a Kubernetes cluster that has permissions to launch other pods.

kubectl apply -f cluster.yaml

kubectl get daskclusters

kubectl get pods -A -l app.kubernetes.io/name=dask-kubernetes-operator

kubectl get svc -l dask.org/cluster-name=simple
kubectl port-forward svc/simple 8786:8786

from dask.distributed import Client
client = Client("localhost:8786")
print(client)

cluster.add_worker_group(name="highmem", n_workers=2, resources={"requests": {"memory": "2Gi"}, "limits": {"memory": "64Gi"}})

cluster.scale(5)
cluster.scale(5, worker_group="highmem")

cluster.delete_worker_group(name="highmem")

kubectl get po -l dask.org/cluster-name=simple


kubectl delete -f cluster.yaml
kubectl delete daskcluster simple


STEPS:
1. Spin up simple kubernetes cluster with GKE
2. Give GKE cluster account permissions
3. Install Helm chart on kubernetes cluster
4. Use external IP address of jupyter service for notebook.







@inproceedings{sawhney_fast_2021,
	address = {Online},
	title = {{FAST}: {Financial} {News} and {Tweet} {Based} {Time} {Aware} {Network} for {Stock} {Trading}},
	shorttitle = {{FAST}},
	url = {https://aclanthology.org/2021.eacl-main.185},
	doi = {10.18653/v1/2021.eacl-main.185},
	abstract = {Designing profitable trading strategies is complex as stock movements are highly stochastic; the market is influenced by large volumes of noisy data across diverse information sources like news and social media. Prior work mostly treats stock movement prediction as a regression or classification task and is not directly optimized towards profit-making. Further, they do not model the fine-grain temporal irregularities in the release of vast volumes of text that the market responds to quickly. Building on these limitations, we propose a novel hierarchical, learning to rank approach that uses textual data to make time-aware predictions for ranking stocks based on expected profit. Our approach outperforms state-of-the-art methods by over 8\% in terms of cumulative profit and risk-adjusted returns in trading simulations on two benchmarks: English tweets and Chinese financial news spanning two major stock indexes and four global markets. Through ablative and qualitative analyses, we build the case for our method as a tool for daily stock trading.},
	urldate = {2023-09-25},
	booktitle = {Proceedings of the 16th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Main} {Volume}},
	publisher = {Association for Computational Linguistics},
	author = {Sawhney, Ramit and Wadhwa, Arnav and Agarwal, Shivam and Shah, Rajiv Ratn},
	month = apr,
	year = {2021},
	pages = {2164--2175},
	file = {Full Text PDF:/home/beer/Zotero/storage/S45LFLMS/Sawhney et al. - 2021 - FAST Financial News and Tweet Based Time Aware Ne.pdf:application/pdf},
}

@article{hagenau_automated_2013,
	title = {Automated news reading: {Stock} price prediction based on financial news using context-capturing features},
	volume = {55},
	issn = {01679236},
	shorttitle = {Automated news reading},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167923613000651},
	doi = {10.1016/j.dss.2013.02.006},
	language = {en},
	number = {3},
	urldate = {2023-09-19},
	journal = {Decision Support Systems},
	author = {Hagenau, Michael and Liebmann, Michael and Neumann, Dirk},
	month = jun,
	year = {2013},
	pages = {685--697},
	file = {Hagenau et al_2013_Automated news reading.pdf:/home/beer/Zotero/storage/G86JSK5K/Hagenau et al_2013_Automated news reading.pdf:application/pdf},
}

@inproceedings{mittermayer_newscats_2006,
	title = {{NewsCATS}: {A} {News} {Categorization} and {Trading} {System}},
	isbn = {978-0-7695-2701-7},
	shorttitle = {{NewsCATS}},
	url = {https://www.computer.org/csdl/proceedings-article/icdm/2006/270101002/12OmNyUWQRU},
	doi = {10.1109/ICDM.2006.115},
	abstract = {NewsCATS is an Automated Text Categorization  (ATC) prototype using a hand-made thesaurus to forecast  intraday stock price trends from information contained in  press releases. Due to a unique labeling approach and by  carefully selecting the appropriate training data News-  CATS achieves a performance which is clearly superior  to other ATC prototypes used for stock price trend forecasting.  In this paper we describe the architecture, training,  and testing of NewsCATS as well as the results of an  extensive robustness analysis.},
	language = {English},
	urldate = {2023-09-16},
	publisher = {IEEE Computer Society},
	author = {Mittermayer, Marc-Andre and Knolmayer, Gerhard F.},
	month = dec,
	year = {2006},
	note = {ISSN: 1550-4786},
	pages = {1002--1007},
	file = {Mittermayer und Knolmayer - 2006 - NewsCATS A News Categorization and Trading System.pdf:/home/beer/Zotero/storage/IUY9V6QD/Mittermayer und Knolmayer - 2006 - NewsCATS A News Categorization and Trading System.pdf:application/pdf},
}

@inproceedings{ding_using_2014,
	address = {Doha, Qatar},
	title = {Using {Structured} {Events} to {Predict} {Stock} {Price} {Movement}: {An} {Empirical} {Investigation}},
	shorttitle = {Using {Structured} {Events} to {Predict} {Stock} {Price} {Movement}},
	url = {https://aclanthology.org/D14-1148},
	doi = {10.3115/v1/D14-1148},
	urldate = {2023-09-16},
	booktitle = {Proceedings of the 2014 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Ding, Xiao and Zhang, Yue and Liu, Ting and Duan, Junwen},
	month = oct,
	year = {2014},
	pages = {1415--1425},
	file = {Ding et al_2014_Using Structured Events to Predict Stock Price Movement.pdf:/home/beer/Zotero/storage/8Q2TRLZM/Ding et al_2014_Using Structured Events to Predict Stock Price Movement.pdf:application/pdf},
}

@misc{peng_leverage_2015,
	title = {Leverage {Financial} {News} to {Predict} {Stock} {Price} {Movements} {Using} {Word} {Embeddings} and {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1506.07220},
	doi = {10.48550/arXiv.1506.07220},
	abstract = {Financial news contains useful information on public companies and the market. In this paper we apply the popular word embedding methods and deep neural networks to leverage financial news to predict stock price movements in the market. Experimental results have shown that our proposed methods are simple but very effective, which can significantly improve the stock prediction accuracy on a standard financial database over the baseline system using only the historical price information.},
	urldate = {2023-09-16},
	publisher = {arXiv},
	author = {Peng, Yangtuo and Jiang, Hui},
	month = jun,
	year = {2015},
	note = {arXiv:1506.07220 [cs]
version: 1},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computational Engineering, Finance, and Science},
	file = {arXiv.org Snapshot:/home/beer/Zotero/storage/K3PYMHDX/1506.html:text/html;Peng_Jiang_2015_Leverage Financial News to Predict Stock Price Movements Using Word Embeddings.pdf:/home/beer/Zotero/storage/VEBM4T7J/Peng_Jiang_2015_Leverage Financial News to Predict Stock Price Movements Using Word Embeddings.pdf:application/pdf},
}

@misc{salbrechter_financial_2021,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Financial {News} {Sentiment} {Learned} by {BERT}: {A} {Strict} {Out}-of-{Sample} {Study}},
	shorttitle = {Financial {News} {Sentiment} {Learned} by {BERT}},
	url = {https://papers.ssrn.com/abstract=3971880},
	doi = {10.2139/ssrn.3971880},
	abstract = {I investigate the impact of financial news on equity returns and introduce a non-parametric model to generate a sentiment signal, which is then used as a predictor for short-term, single-stock equity return forecasts. I build on Google’s BERT model and sequentially pre-train and fine-tune it using Thomson Reuters financial news data covering the period from 1996 to 2020. With daily returndata of S\&P 500 constituents, the analysis shows that financial news carry information that is not immediately reflected in equity prices. News is largely priced-in within one day, with diffusion varying across industries. A trading strategy that leverages the sentiment signal generates an average return per trade of 24.06 bps over an 18 year out-of-sample period.},
	language = {en},
	urldate = {2023-09-04},
	author = {Salbrechter, Stefan},
	month = nov,
	year = {2021},
	keywords = {BERT, Machine Learning, NLP, Return Predictability, Sentiment Analysis, Text Mining},
	file = {Salbrechter_2021_Financial News Sentiment Learned by BERT.pdf:/home/beer/Zotero/storage/NCZZNENT/Salbrechter_2021_Financial News Sentiment Learned by BERT.pdf:application/pdf},
}

@article{liu_intraday_2023,
	title = {Intraday {Stock} {Predictability} {Everywhere}},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=4496917},
	doi = {10.2139/ssrn.4496917},
	abstract = {With approximately 900 million observations we conduct, to our knowledge, the largest study ever of intraday stock return predictability using machine learning techniques finding consistent out-of-sample predictability across market, sector, and individual stock returns at various time horizons. While linear models have the strongest statistical predictive power, nonlinear models economically dominate them and machine learning intraday long-short portfolios based on their forecasts attain Sharpe ratios of 4 after transaction costs. Predictability is short-lived, highest in the middle of the day, and more pronounced for less liquid firms, which indicates that slow-moving capital is an economic source of mispricing.},
	language = {en},
	urldate = {2023-08-04},
	journal = {SSRN Electronic Journal},
	author = {Liu, Fred and Stentoft, Lars},
	year = {2023},
	file = {Liu und Stentoft - 2023 - Intraday Stock Predictability Everywhere.pdf:/home/beer/Zotero/storage/C5QTK47Y/Liu und Stentoft - 2023 - Intraday Stock Predictability Everywhere.pdf:application/pdf},
}

@inproceedings{ding_deep_2015,
	address = {Buenos Aires, Argentina},
	series = {{IJCAI}'15},
	title = {Deep learning for event-driven stock prediction},
	isbn = {978-1-57735-738-4},
	abstract = {We propose a deep learning method for event-driven stock market prediction. First, events are extracted from news text, and represented as dense vectors, trained using a novel neural tensor network. Second, a deep convolutional neural network is used to model both short-term and long-term influences of events on stock price movements. Experimental results show that our model can achieve nearly 6\% improvements on S\&P 500 index prediction and individual stock prediction, respectively, compared to state-of-the-art baseline methods. In addition, market simulation results show that our system is more capable of making profits than previously reported systems trained on S\&P 500 stock historical data.},
	urldate = {2023-09-27},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Artificial} {Intelligence}},
	publisher = {AAAI Press},
	author = {Ding, Xiao and Zhang, Yue and Liu, Ting and Duan, Junwen},
	month = jul,
	year = {2015},
	pages = {2327--2333},
	file = {Ding et al_2015_Deep learning for event-driven stock prediction.pdf:/home/beer/Zotero/storage/F5WPR9HC/Ding et al_2015_Deep learning for event-driven stock prediction.pdf:application/pdf},
}

@misc{bushee_linguistic_2017,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Linguistic {Complexity} in {Firm} {Disclosures}: {Obfuscation} or {Information}?},
	shorttitle = {Linguistic {Complexity} in {Firm} {Disclosures}},
	url = {https://papers.ssrn.com/abstract=2375424},
	doi = {10.2139/ssrn.2375424},
	abstract = {Prior research generally interprets complex language in firms’ disclosures as indicative of managerial obfuscation. However, complex language can also reflect the provision of complex information, e.g., informative technical disclosure. As a consequence, linguistic complexity commingles two latent components — obfuscation and information — that are related to information asymmetry in opposite directions. We develop a novel empirical approach to estimate these two latent components within the context of quarterly earnings conference calls. We validate our estimates of these two latent components by examining their relation to information asymmetry. Consistent with our predictions, we find that our estimate of the information component is negatively associated with information asymmetry while our estimate of the obfuscation component is positively associated with information asymmetry. Our findings suggest that future research on linguistic complexity can construct more powerful tests by separately examining these two latent components of linguistic complexity.},
	language = {en},
	urldate = {2023-09-27},
	author = {Bushee, Brian J. and Gow, Ian D. and Taylor, Daniel J.},
	month = jun,
	year = {2017},
	keywords = {Conference calls, Disclosure, Information asymmetry, Linguistic complexity},
	file = {Full Text PDF:/home/beer/Zotero/storage/B6YMXB36/Bushee et al. - 2017 - Linguistic Complexity in Firm Disclosures Obfusca.pdf:application/pdf},
}

@article{leinweber_event-driven_2011,
	title = {Event-{Driven} {Trading} and the “{New} {News}”},
	volume = {38},
	issn = {0095-4918, 2168-8656},
	url = {https://www.pm-research.com/content/iijpormgmt/38/1/110},
	doi = {10.3905/jpm.2011.38.1.110},
	abstract = {{\textless}p{\textgreater}Two information revolutions are underway in trading and investing. Most headlines focus on structured quantitative market information at ever higher frequencies, but the other technology revolution in trading and investing is driven by qualitative, textual, and relationship information. The IBM computer Watson’s overwhelming Jeopardy victory demonstrated how good machines can get at this. News analysis is a focus of language technology in finance. In this article, Leinweber and Sisk include event studies and show U.S. portfolio simulation results for “pure news” signals applied over the period 2006–2009 as well as a true out-of-sample period in 2010, which indicates alpha in excess of 10\% a year. The authors also describe other applications of automated qualitative analysis for information-driven social media client relations.{\textless}/p{\textgreater}{\textless}p{\textgreater}{\textless}bold{\textgreater}TOPICS:{\textless}/bold{\textgreater} {\textless}ext-link{\textgreater}Equity portfolio management{\textless}/ext-link{\textgreater}, {\textless}ext-link{\textgreater}big data/machine learning{\textless}/ext-link{\textgreater}, {\textless}ext-link{\textgreater}security analysis and valuation{\textless}/ext-link{\textgreater}{\textless}/p{\textgreater}},
	language = {en},
	number = {1},
	urldate = {2023-09-27},
	journal = {The Journal of Portfolio Management},
	author = {Leinweber, David and Sisk, Jacob},
	month = oct,
	year = {2011},
	note = {Company: Institutional Investor Journals
Distributor: Institutional Investor Journals
Institution: Institutional Investor Journals
Label: Institutional Investor Journals
Publisher: Portfolio Management Research
Section: Asset Classes},
	pages = {110--124},
	file = {Leinweber und Sisk - 2011 - Event-Driven Trading and the “New News”.pdf:/home/beer/Zotero/storage/2M62YTNM/Leinweber und Sisk - 2011 - Event-Driven Trading and the “New News”.pdf:application/pdf},
}

@misc{dangl_overnight_2022,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Overnight {Reversal} and the {Asymmetric} {Reaction} to {News}},
	url = {https://papers.ssrn.com/abstract=4307675},
	doi = {10.2139/ssrn.4307675},
	abstract = {News released overnight has a significant directional impact on individual shares’ opening prices, i.e., the market tends to open higher (lower) when news with positive (negative) sentiment is published. However, the market opening is not fully efficient due to over- or underreactions of market participants to the news, resulting in a predictable pattern of returns on the following trading day. In particular, we find that large daytime returns followed by overnight news with strong sentiment lead to a predictable return reversal during the subsequent trading day. This predictable reversal is present independent of the polarity of the news sentiment. Without overnight news, large previous-day returns only have marginal predictive power.},
	language = {en},
	urldate = {2023-09-27},
	author = {Dangl, Thomas and Salbrechter, Stefan},
	month = dec,
	year = {2022},
	keywords = {BERT, Machine Learning, Return Predictability, Sentiment Analysis, Text Mining, Overnight Returns},
	file = {Full Text PDF:/home/beer/Zotero/storage/9EV2W99F/Dangl and Salbrechter - 2022 - Overnight Reversal and the Asymmetric Reaction to .pdf:application/pdf},
}

@inproceedings{kilimci_financial_2019,
	title = {Financial {Sentiment} {Analysis} for {Predicting} {Direction} of {Stocks} using {Bidirectional} {Encoder} {Representations} from {Transformers} ({BERT}) and {Deep} {Learning} {Models}},
	doi = {10.17758/URUAE8.UL12191013},
	abstract = {Stocks are an important type of investment that is affected by the economic crisis. For this reason, forecasting the direction of stocks is a significant for investors, analysts, and researchers. In this study, we propose to predict the direction of stocks in Turkish stock market (BIST100) by employing Turkish texts such as social media platforms. For this purpose, different deep learning methodologies such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Long Short Term Memory Networks (LSTMs) and a new generation natural language processing model, namely Bidirectional Encoder Representations from Transformers (BERT) are employed for classification task. To the best of our knowledge, this is the first study for analyzing the direction of stocks by using both CNN, RNN, LSTM, BERT and texts from social media platforms. Experimental results represent that the utilization of deep learning models and a new generation word embedding model which is called BERT boosts the classification performance. In conclusion, using deep learning algorithms and a new generation of natural language processing model provide a valuable contribution to investors presents 96.26\% of accuracy performance by predicting direction of stocks.},
	author = {Kilimci, Zeynep and Othan, Derya and Uysal, Mitat},
	month = dec,
	year = {2019},
	file = {Full Text PDF:/home/beer/Zotero/storage/4Y9CGZ85/Kilimci et al. - 2019 - Financial Sentiment Analysis for Predicting Direct.pdf:application/pdf},
}

@inproceedings{wei_stock_2020,
	title = {Stock {Trend} {Prediction} using {Financial} {Market} {News} and {BERT}},
	doi = {10.5220/0010172103250332},
	author = {Wei, Feng and Nguyen, Uyen},
	month = jan,
	year = {2020},
	pages = {325--332},
	file = {Full Text PDF:/home/beer/Zotero/storage/2Z2ISJKR/Wei und Nguyen - 2020 - Stock Trend Prediction using Financial Market News.pdf:application/pdf},
}

@inproceedings{sousa_bert_2019,
	title = {{BERT} for {Stock} {Market} {Sentiment} {Analysis}},
	doi = {10.1109/ICTAI.2019.00231},
	author = {Sousa, Matheus and Sakiyama, Kenzo and Rodrigues, Lucas and de Moraes, Pedro and Fernandes, Eraldo and Matsubara, Edson},
	month = nov,
	year = {2019},
	pages = {1597--1601},
	file = {Full Text PDF:/home/beer/Zotero/storage/6FXVDYJL/Sousa et al. - 2019 - BERT for Stock Market Sentiment Analysis.pdf:application/pdf},
}

@article{fazlija_using_2022,
	title = {Using {Financial} {News} {Sentiment} for {Stock} {Price} {Direction} {Prediction}},
	volume = {10},
	url = {https://ideas.repec.org//a/gam/jmathe/v10y2022i13p2156-d843797.html},
	abstract = {Using sentiment information in the analysis of financial markets has attracted much attention. Natural language processing methods can be used to extract market sentiment information from texts such as news articles. The objective of this paper is to extract financial market sentiment information from news articles and use the estimated sentiment scores to predict the price direction of the stock market index Standard \& Poor’s 500. To achieve the best possible performance in sentiment classification, state-of-the-art bidirectional encoder representations from transformers (BERT) models are used. The pretrained transformer networks are fine-tuned on a labeled financial text dataset and applied to news articles from known providers of financial news content to predict their sentiment scores. The generated sentiment scores for the titles of the given news articles, for the (text) content of said news articles, and for the combined title-content consideration are posited against past time series information of the stock market index. To forecast the price direction of the stock market index, the predicted sentiment scores are used in a simple strategy and as features for a random forest classifier. The results show that sentiment scores based on news content are particularly useful for stock price direction prediction.},
	language = {en},
	number = {13},
	urldate = {2023-10-23},
	journal = {Mathematics},
	author = {Fazlija, Bledar and Harder, Pedro},
	year = {2022},
	note = {Publisher: MDPI},
	keywords = {machine learning, natural language processing, sentiment analysis, stock prize prediction},
	pages = {1--20},
	file = {Fazlija und Harder - 2022 - Using Financial News Sentiment for Stock Price Dir.pdf:/home/beer/Zotero/storage/F495SX6A/Fazlija und Harder - 2022 - Using Financial News Sentiment for Stock Price Dir.pdf:application/pdf;Snapshot:/home/beer/Zotero/storage/7LTVTW5J/v10y2022i13p2156-d843797.html:text/html},
}

@inproceedings{hakim_automated_2014,
	title = {Automated document classification for news article in {Bahasa} {Indonesia} based on term frequency inverse document frequency ({TF}-{IDF}) approach},
	url = {https://ieeexplore.ieee.org/document/7007894},
	doi = {10.1109/ICITEED.2014.7007894},
	abstract = {The exponential growth of the data may lead us to the information explosion era, an era where most of the data cannot be managed easily. Text mining study is believed to prevent the world from entering that era. One of the text mining studies that may prevent the explosion era is text classification. It is a way to classify articles into several predefined categories. In this research, the classifier implements TF-IDF algorithm. TF-IDF is an algorithm that counts the word weight by considering frequency of the word (TF) and in how many files the word can be found (IDF). Since the IDF could see the in how many files a term can be found, it can control the weight of each word. When a word can be found in so many files, it will be considered as an unimportant word. TF-IDF has been proven to create a classifier that could classify news articles in Bahasa Indonesia in a high accuracy; 98.3\%.},
	urldate = {2023-10-14},
	booktitle = {2014 6th {International} {Conference} on {Information} {Technology} and {Electrical} {Engineering} ({ICITEE})},
	author = {Hakim, Ari Aulia and Erwin, Alva and Eng, Kho I and Galinium, Maulahikmah and Muliady, Wahyu},
	month = oct,
	year = {2014},
	pages = {1--4},
	file = {Hakim et al. - 2014 - Automated document classification for news article.pdf:/home/beer/Zotero/storage/GYFJICS5/Hakim et al. - 2014 - Automated document classification for news article.pdf:application/pdf;IEEE Xplore Abstract Record:/home/beer/Zotero/storage/N6Q4CUVD/7007894.html:text/html},
}

@misc{chen_stock_2021,
	title = {Stock {Movement} {Prediction} with {Financial} {News} using {Contextualized} {Embedding} from {BERT}},
	url = {http://arxiv.org/abs/2107.08721},
	doi = {10.48550/arXiv.2107.08721},
	abstract = {News events can greatly influence equity markets. In this paper, we are interested in predicting the short-term movement of stock prices after financial news events using only the headlines of the news. To achieve this goal, we introduce a new text mining method called Fine-Tuned Contextualized-Embedding Recurrent Neural Network (FT-CE-RNN). Compared with previous approaches which use static vector representations of the news (static embedding), our model uses contextualized vector representations of the headlines (contextualized embeddings) generated from Bidirectional Encoder Representations from Transformers (BERT). Our model obtains the state-of-the-art result on this stock movement prediction task. It shows significant improvement compared with other baseline models, in both accuracy and trading simulations. Through various trading simulations based on millions of headlines from Bloomberg News, we demonstrate the ability of this model in real scenarios.},
	urldate = {2023-10-13},
	publisher = {arXiv},
	author = {Chen, Qinkai},
	month = jul,
	year = {2021},
	note = {arXiv:2107.08721 [cs, q-fin]},
	keywords = {Computer Science - Computation and Language, Quantitative Finance - Statistical Finance, 91-10, Computer Science - Machine Learning, I.2.7, J.4, Quantitative Finance - Portfolio Management},
	file = {arXiv Fulltext PDF:/home/beer/Zotero/storage/EP7DV7NQ/Chen - 2021 - Stock Movement Prediction with Financial News usin.pdf:application/pdf;arXiv.org Snapshot:/home/beer/Zotero/storage/GEX2QY2G/2107.html:text/html},
}

@misc{araci_finbert_2019,
	title = {{FinBERT}: {Financial} {Sentiment} {Analysis} with {Pre}-trained {Language} {Models}},
	shorttitle = {{FinBERT}},
	url = {http://arxiv.org/abs/1908.10063},
	doi = {10.48550/arXiv.1908.10063},
	abstract = {Financial sentiment analysis is a challenging task due to the specialized language and lack of labeled data in that domain. General-purpose models are not effective enough because of the specialized language used in a financial context. We hypothesize that pre-trained language models can help with this problem because they require fewer labeled examples and they can be further trained on domain-specific corpora. We introduce FinBERT, a language model based on BERT, to tackle NLP tasks in the financial domain. Our results show improvement in every measured metric on current state-of-the-art results for two financial sentiment analysis datasets. We find that even with a smaller training set and fine-tuning only a part of the model, FinBERT outperforms state-of-the-art machine learning methods.},
	urldate = {2023-10-05},
	publisher = {arXiv},
	author = {Araci, Dogu},
	month = aug,
	year = {2019},
	note = {arXiv:1908.10063 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/beer/Zotero/storage/QLE332MZ/Araci - 2019 - FinBERT Financial Sentiment Analysis with Pre-tra.pdf:application/pdf;arXiv.org Snapshot:/home/beer/Zotero/storage/XWUYMWH5/1908.html:text/html},
}

@misc{ke_predicting_2020,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Predicting {Returns} with {Text} {Data}},
	url = {https://papers.ssrn.com/abstract=3389884},
	doi = {10.2139/ssrn.3389884},
	abstract = {We introduce a new text-mining methodology that extracts information from news articles to predict asset returns. Unlike more common sentiment scores used for stock return prediction (e.g., those sold by commercial vendors or built with dictionary-based methods), our supervised learning framework constructs a score that is specifically adapted to the problem of return prediction. Our method proceeds in three steps: 1) isolating a list of terms via predictive screening, 2) assigning prediction weights to these words via topic modeling, and 3) aggregating terms into an article-level predictive score via penalized likelihood. We derive theoretical guarantees on the accuracy of estimates from our model with minimal assumptions. In our empirical analysis, we study one of the most actively monitored streams of news articles in the financial system--the Dow Jones Newswires--and show that our supervised text model excels at extracting return-predictive signals in this context. Information in newswires is assimilated into prices with an ineffcient delay that is broadly consistent with limits-to-arbitrage (i.e., more severe for smaller and more volatile firms) yet can be exploited in a real-time trading strategy with reasonable turnover and net of transaction costs.},
	language = {en},
	urldate = {2023-10-05},
	author = {Ke, Zheng Tracy and Kelly, Bryan T. and Xiu, Dacheng},
	month = sep,
	year = {2020},
	keywords = {Machine Learning, Return Predictability, Sentiment Analysis, Text Mining, Penalized Likelihood, Screening, Topic Modeling},
	file = {Full Text PDF:/home/beer/Zotero/storage/CD7HXQFE/Ke et al. - 2020 - Predicting Returns with Text Data.pdf:application/pdf},
}

@article{lv_empirical_2019,
	title = {An {Empirical} {Study} of {Machine} {Learning} {Algorithms} for {Stock} {Daily} {Trading} {Strategy}},
	volume = {2019},
	issn = {1024-123X, 1563-5147},
	url = {https://www.hindawi.com/journals/mpe/2019/7816154/},
	doi = {10.1155/2019/7816154},
	abstract = {According to the forecast of stock price trends, investors trade stocks. In recent years, many researchers focus on adopting machine learning (ML) algorithms to predict stock price trends. However, their studies were carried out on small stock datasets with limited features, short backtesting period, and no consideration of transaction cost. And their experimental results lack statistical significance test. In this paper, on large-scale stock datasets, we synthetically evaluate various ML algorithms and observe the daily trading performance of stocks under transaction cost and no transaction cost. Particularly, we use two large datasets of 424 S\&P 500 index component stocks (SPICS) and 185 CSI 300 index component stocks (CSICS) from 2010 to 2017 and compare six traditional ML algorithms and six advanced deep neural network (DNN) models on these two datasets, respectively. The experimental results demonstrate that traditional ML algorithms have a better performance in most of the directional evaluation indicators. Unexpectedly, the performance of some traditional ML algorithms is not much worse than that of the best DNN models without considering the transaction cost. Moreover, the trading performance of all ML algorithms is sensitive to the changes of transaction cost. Compared with the traditional ML algorithms, DNN models have better performance considering transaction cost. Meanwhile, the impact of transparent transaction cost and implicit transaction cost on trading performance are different. Our conclusions are significant to choose the best algorithm for stock trading in different markets.},
	language = {en},
	urldate = {2023-12-12},
	journal = {Mathematical Problems in Engineering},
	author = {Lv, Dongdong and Yuan, Shuhan and Li, Meizi and Xiang, Yang},
	month = apr,
	year = {2019},
	pages = {1--30},
	file = {Lv et al. - 2019 - An Empirical Study of Machine Learning Algorithms .pdf:/home/beer/Zotero/storage/RU6CXJAY/Lv et al. - 2019 - An Empirical Study of Machine Learning Algorithms .pdf:application/pdf},
}

@misc{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	doi = {10.48550/arXiv.1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2023-12-12},
	publisher = {arXiv},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	note = {arXiv:1810.04805 [cs]},
	keywords = {Computer Science - Computation and Language, BERT, neural network, transformer},
	file = {arXiv Fulltext PDF:/home/beer/Zotero/storage/CEK9XRX8/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf;arXiv.org Snapshot:/home/beer/Zotero/storage/MQMZIDLV/1810.html:text/html},
}

@inproceedings{polignano_alberto_2019,
	title = {{ALBERTO}: {Italian} {BERT} {Language} {Understanding} {Model} for {NLP} {Challenging} {Tasks} {Based} on {Tweets}},
	shorttitle = {{ALBERTO}},
	abstract = {Recent scientific studies on natural language processing (NLP) report the outstanding effectiveness observed in the use of context-dependent and task-free language understanding models such as ELMo, GPT, and BERT. Specifically, they have proved to achieve state of the art performance in numerous complex NLP tasks such as question answering and sentiment analysis in the English language. Following the great popularity and effectiveness that these models are gaining in the scientific community, we trained a BERT language understanding model for the Italian language (AlBERTo). In particular , AlBERTo is focused on the language used in social networks, specifically on Twitter. To demonstrate its ro-bustness, we evaluated AlBERTo on the EVALITA 2016 task SENTIPOLC (SEN-TIment POLarity Classification) obtaining state of the art results in subjectiv-ity, polarity and irony detection on Ital-ian tweets. The pre-trained AlBERTo model will be publicly distributed through the GitHub platform at the following web address: https://github.com/ marcopoli/AlBERTo-it in order to facilitate future research.},
	author = {Polignano, Marco and Basile, Pierpaolo and de Gemmis, Marco and Semeraro, Giovanni and Basile, Valerio},
	month = nov,
	year = {2019},
	file = {Full Text PDF:/home/beer/Zotero/storage/FRM4I7GC/Polignano et al. - 2019 - ALBERTO Italian BERT Language Understanding Model.pdf:application/pdf},
}

@misc{sonkiya_stock_2021,
	title = {Stock price prediction using {BERT} and {GAN}},
	url = {http://arxiv.org/abs/2107.09055},
	doi = {10.48550/arXiv.2107.09055},
	abstract = {The stock market has been a popular topic of interest in the recent past. The growth in the inflation rate has compelled people to invest in the stock and commodity markets and other areas rather than saving. Further, the ability of Deep Learning models to make predictions on the time series data has been proven time and again. Technical analysis on the stock market with the help of technical indicators has been the most common practice among traders and investors. One more aspect is the sentiment analysis - the emotion of the investors that shows the willingness to invest. A variety of techniques have been used by people around the globe involving basic Machine Learning and Neural Networks. Ranging from the basic linear regression to the advanced neural networks people have experimented with all possible techniques to predict the stock market. It's evident from recent events how news and headlines affect the stock markets and cryptocurrencies. This paper proposes an ensemble of state-of-the-art methods for predicting stock prices. Firstly sentiment analysis of the news and the headlines for the company Apple Inc, listed on the NASDAQ is performed using a version of BERT, which is a pre-trained transformer model by Google for Natural Language Processing (NLP). Afterward, a Generative Adversarial Network (GAN) predicts the stock price for Apple Inc using the technical indicators, stock indexes of various countries, some commodities, and historical prices along with the sentiment scores. Comparison is done with baseline models like - Long Short Term Memory (LSTM), Gated Recurrent Units (GRU), vanilla GAN, and Auto-Regressive Integrated Moving Average (ARIMA) model.},
	urldate = {2023-12-27},
	publisher = {arXiv},
	author = {Sonkiya, Priyank and Bajpai, Vikas and Bansal, Anukriti},
	month = jul,
	year = {2021},
	note = {arXiv:2107.09055 [cs, q-fin]},
	keywords = {Computer Science - Computation and Language, Quantitative Finance - Statistical Finance, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/beer/Zotero/storage/Y9CAGL3S/Sonkiya et al. - 2021 - Stock price prediction using BERT and GAN.pdf:application/pdf;arXiv.org Snapshot:/home/beer/Zotero/storage/J3XLP3QZ/2107.html:text/html},
}

@inproceedings{martinez_artificial_2009,
	title = {From an artificial neural network to a stock market day-trading system: {A} case study on the {BM}\&{F} {BOVESPA}},
	shorttitle = {From an artificial neural network to a stock market day-trading system},
	doi = {10.1109/IJCNN.2009.5179050},
	abstract = {Predicting trends in the stock market is a subject of major interest for both scholars and financial analysts. The main difficulties of this problem are related to the dynamic, complex, evolutive and chaotic nature of the markets. In order to tackle these problems, this work proposes a day-trading system that ldquotranslatesrdquo the outputs of an artificial neural network into business decisions, pointing out to the investors the best times to trade and make profits. The ANN forecasts the lowest and highest stock prices of the current trading day. The system was tested with the two main stocks of the BM\&FBOVESPA, an important and understudied market. A series of experiments were performed using different data input configurations, and compared with four benchmarks. The results were evaluated using both classical evaluation metrics, such as the ANN generalization error, and more general metrics, such as the annualized return. The ANN showed to be more accurate and give more return to the investor than the four benchmarks. The best results obtained by the ANN had an mean absolute percentage error around 50\% smaller than the best benchmark, and doubled the capital of the investor.},
	author = {Martinez, Leonardo and Hora, Diego and Palotti, João and Meira Jr, Wagner and Pappa, Gisele},
	month = jun,
	year = {2009},
	keywords = {ann, model output, trading system},
	pages = {2006--2013},
	file = {Full Text PDF:/home/beer/Zotero/storage/V9PE7NUL/Martinez et al. - 2009 - From an artificial neural network to a stock marke.pdf:application/pdf},
}

@book{chande_beyond_2001,
	title = {Beyond technical analysis: {How} to develop and implement a winning trading system},
	volume = {101},
	publisher = {John Wiley \& Sons},
	author = {Chande, Tushar S},
	year = {2001},
	file = {Chande - 2001 - Beyond technical analysis How to develop and impl.pdf:/home/beer/Zotero/storage/3LVP9PVV/Chande - 2001 - Beyond technical analysis How to develop and impl.pdf:application/pdf},
}

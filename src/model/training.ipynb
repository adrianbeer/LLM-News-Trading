{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GUGkJ0V3lUT"
      },
      "outputs": [],
      "source": [
        "google_colab = False\n",
        "if google_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    cwd=\"/content/drive/MyDrive/NewsTrading/trading_bot\"\n",
        "    %cd /content/drive/MyDrive/NewsTrading/trading_bot\n",
        "    %pip install -r requirements_clean.txt\n",
        "    !git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "    !python rapidsai-csp-utils/colab/pip-install.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HZjfWVr73qUs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[autoreload of src.model.neural_network failed: Traceback (most recent call last):\n",
            "  File \"g:\\Meine Ablage\\NewsTrading\\trading_bot\\.venv\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "  File \"g:\\Meine Ablage\\NewsTrading\\trading_bot\\.venv\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 500, in superreload\n",
            "    update_generic(old_obj, new_obj)\n",
            "  File \"g:\\Meine Ablage\\NewsTrading\\trading_bot\\.venv\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 397, in update_generic\n",
            "    update(a, b)\n",
            "  File \"g:\\Meine Ablage\\NewsTrading\\trading_bot\\.venv\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 349, in update_class\n",
            "    if update_generic(old_obj, new_obj):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"g:\\Meine Ablage\\NewsTrading\\trading_bot\\.venv\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 397, in update_generic\n",
            "    update(a, b)\n",
            "  File \"g:\\Meine Ablage\\NewsTrading\\trading_bot\\.venv\\Lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 309, in update_function\n",
            "    setattr(old, name, getattr(new, name))\n",
            "ValueError: __init__() requires a code object with 0 free vars, not 1752346656769\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from transformers import BertTokenizerFast, get_linear_schedule_with_warmup\n",
        "from src.model.data_loading import get_data_loader_from_dataset\n",
        "from src.config import config, MODEL_CONFIG\n",
        "from src.model.neural_network import train, MyBertModule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Settings\n",
        "target_col_name = MODEL_CONFIG.target_col_name\n",
        "bert_model_name = MODEL_CONFIG.transformer_hugface_id\n",
        "FROM_SCRATCH = True\n",
        "batch_size = 2\n",
        "epochs = 1\n",
        "tokenizer = BertTokenizerFast.from_pretrained(bert_model_name)\n",
        "loss_function = MODEL_CONFIG.loss_function\n",
        "learning_rate = 0.01 # 5e-5 (slow) for bert, 0.3 (fast) for new feed forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Current PyTorch version: 2.1.1+cu118 (should be 2.x+)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pt_version = torch.__version__\n",
        "print(f\"[INFO] Current PyTorch version: {pt_version} (should be 2.x+)\")\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pHvtsu8M4cJg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "419094"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download dataset\n",
        "dataset = pd.read_parquet(config.data.merged)\n",
        "dataset.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nthFIAsg4fh9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "254166\n",
            "247271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Adria\\AppData\\Local\\Temp\\ipykernel_47176\\183389681.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset.dropna(inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Filter out Stocks... TODO: put this into filter interface and make configurable in model_config\n",
        "dataset = dataset[\n",
        "    (dataset[\"unadj_open\"] >= 2) &          # penny stocks\n",
        "    (dataset[\"dollar_volume\"] >= 30_000) &  # illiquid stocks TODO: this has look-ahead bias\n",
        "    (dataset[\"staleness\"] <= 0.9)           # repeat news\n",
        "                  ]\n",
        "print(dataset.shape[0])\n",
        "dataset.dropna(inplace=True)\n",
        "print(dataset.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "173089 samples in training set.\n",
            " 49454 samples in validation set.\n",
            " 24728 samples in testing set.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "g:\\Meine Ablage\\NewsTrading\\trading_bot\\src\\model\\splits.py:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dat[\"split\"] = \"training\"\n",
            "g:\\Meine Ablage\\NewsTrading\\trading_bot\\src\\model\\splits.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dat[\"split\"] = dat[\"split\"].astype(\"category\")\n"
          ]
        }
      ],
      "source": [
        "dataset: pd.DataFrame = MODEL_CONFIG.splitter.add_splits(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIkre90J4bGA",
        "outputId": "01fdbb7e-790a-4e26-af7f-eddd99489c0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset.index.name=None\n"
          ]
        }
      ],
      "source": [
        "train_dataloader = get_data_loader_from_dataset(dataset=dataset,\n",
        "                                                split=\"training\",\n",
        "                                                batch_size=batch_size,\n",
        "                                                label_col=target_col_name,\n",
        "                                                data_loader_kwargs=dict(shuffle=True,\n",
        "                                                                        pin_memory=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset.index.name=None\n"
          ]
        }
      ],
      "source": [
        "validation_dataloader = get_data_loader_from_dataset(dataset=dataset,\n",
        "                                                split=\"validation\",\n",
        "                                                batch_size=batch_size,\n",
        "                                                label_col=target_col_name,\n",
        "                                                data_loader_kwargs=dict(shuffle=True,\n",
        "                                                                        pin_memory=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i-dNsG_3hN5",
        "outputId": "bfa57c74-5913-4404-b8a4-3bca24d9262f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device=device(type='cuda')\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[26], line 28\u001b[0m\n\u001b[0;32m     23\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m get_linear_schedule_with_warmup(optimizer,\n\u001b[0;32m     24\u001b[0m                                             num_warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     25\u001b[0m                                             num_training_steps\u001b[38;5;241m=\u001b[39mtotal_steps)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m model, training_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                              \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mvalidation_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mclip_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m df_stats \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39mtraining_stats)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_stats)\n",
            "File \u001b[1;32mg:\\Meine Ablage\\NewsTrading\\trading_bot\\src\\model\\neural_network.py:121\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, scheduler, loss_function, epochs, train_dataloader, validation_dataloader, device, clip_value)\u001b[0m\n\u001b[0;32m    118\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m--> 121\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     avg_train_loss \u001b[38;5;241m=\u001b[39m epoch_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n\u001b[0;32m    124\u001b[0m     training_time \u001b[38;5;241m=\u001b[39m format_time(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0)\n",
            "File \u001b[1;32mg:\\Meine Ablage\\NewsTrading\\trading_bot\\src\\model\\neural_network.py:91\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, train_dataloader, device, loss_function, clip_value, optimizer, scheduler, t0)\u001b[0m\n\u001b[0;32m     87\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     89\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39minputs)     \n\u001b[1;32m---> 91\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m loss_function(outputs\u001b[38;5;241m.\u001b[39msqueeze(), \n\u001b[0;32m     92\u001b[0m                     batch_labels\u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[0;32m     93\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Calculate gradients\u001b[39;00m\n",
            "File \u001b[1;32mg:\\Meine Ablage\\NewsTrading\\trading_bot\\src\\model\\neural_network.py:91\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, train_dataloader, device, loss_function, clip_value, optimizer, scheduler, t0)\u001b[0m\n\u001b[0;32m     87\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     89\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39minputs)     \n\u001b[1;32m---> 91\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m loss_function(outputs\u001b[38;5;241m.\u001b[39msqueeze(), \n\u001b[0;32m     92\u001b[0m                     batch_labels\u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[0;32m     93\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Calculate gradients\u001b[39;00m\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mg:\\Meine Ablage\\NewsTrading\\trading_bot\\.venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
            "File \u001b[1;32mg:\\Meine Ablage\\NewsTrading\\trading_bot\\.venv\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model: nn.Module = MODEL_CONFIG.neural_net(bert_model_name=MODEL_CONFIG.transformer_hugface_id, \n",
        "                                            num_classes=3)\n",
        "\n",
        "if MODEL_CONFIG.input_params_path:\n",
        "    model.load_state_dict(torch.load(MODEL_CONFIG.input_params_path))\n",
        "    \n",
        "MyBertModule.deactivate_learning_for_layer(model.bert)\n",
        "\n",
        "# .compile currently isn't supported for Windows\n",
        "# model = torch.compile(model)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"{device=}\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Optimizer, scheduler and loss function\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
        "\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0,\n",
        "                                                num_training_steps=total_steps)\n",
        "\n",
        "    # Training\n",
        "    model, training_stats = train(model,\n",
        "                                  optimizer,\n",
        "                                  scheduler,\n",
        "                                  loss_function,\n",
        "                                  epochs,\n",
        "                                  train_dataloader,\n",
        "                                  validation_dataloader,\n",
        "                                  device,\n",
        "                                  clip_value=2)\n",
        "\n",
        "    df_stats = pd.DataFrame(data=training_stats)\n",
        "    print(df_stats)\n",
        "\n",
        "    # Store Model\n",
        "    torch.save(model.state_dict(), MODEL_CONFIG.output_params_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oQsYufL7R8M"
      },
      "outputs": [],
      "source": [
        "if google_colab:\n",
        "    from google.colab import runtime\n",
        "    runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a85t-TV27Uvs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "6GUGkJ0V3lUT"
   },
   "outputs": [],
   "source": [
    "google_colab = False\n",
    "if google_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    cwd=\"/content/drive/MyDrive/NewsTrading/trading_bot\"\n",
    "    %cd /content/drive/MyDrive/NewsTrading/trading_bot\n",
    "    %pip install -r requirements_clean.txt\n",
    "    !git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
    "    !python rapidsai-csp-utils/colab/pip-install.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "HZjfWVr73qUs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizerFast\n",
    "from src.model.data_loading import get_data_loader_from_dataset\n",
    "from src.config import config, MODEL_CONFIG\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "target_col_name = MODEL_CONFIG.target_col_name\n",
    "bert_model_name = MODEL_CONFIG.transformer_hugface_id\n",
    "batch_size = 4\n",
    "epochs = 1\n",
    "tokenizer = BertTokenizerFast.from_pretrained(bert_model_name)\n",
    "learning_rate = 0.01 # 5e-5 (slow) for bert, 0.3 (fast) for new feed forward\n",
    "is_deactivated_bert_learning = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current PyTorch version: 2.1.1+cu118 (should be 2.x+)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_version = torch.__version__\n",
    "print(f\"[INFO] Current PyTorch version: {pt_version} (should be 2.x+)\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "pHvtsu8M4cJg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download dataset\n",
    "dataset = pd.read_parquet(config.data.merged).iloc[-20000:]\n",
    "dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "nthFIAsg4fh9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10819\n",
      "10413\n"
     ]
    }
   ],
   "source": [
    "# Filter out Stocks... TODO: put this into filter interface and make configurable in model_config\n",
    "dataset = dataset[\n",
    "    (dataset[\"unadj_open\"] >= 2) &          # penny stocks\n",
    "    (dataset[\"dollar_volume\"] >= 30_000)  # illiquid stocks TODO: this has look-ahead bias\n",
    "                  ]\n",
    "# TODO: Staleness has yet to be calculated\n",
    "if \"staleness\" in dataset.columns:\n",
    "    dataset = dataset[(dataset[\"staleness\"] <= 0.9)] # repeat news\n",
    "\n",
    "print(dataset.shape[0])\n",
    "dataset.dropna(inplace=True)\n",
    "print(dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7289 samples in training set.\n",
      " 2082 samples in validation set.\n",
      " 1042 samples in testing set.\n"
     ]
    }
   ],
   "source": [
    "dataset: pd.DataFrame = MODEL_CONFIG.splitter.add_splits(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PIkre90J4bGA",
    "outputId": "01fdbb7e-790a-4e26-af7f-eddd99489c0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.index.name=None\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = get_data_loader_from_dataset(dataset=dataset,\n",
    "                                                split=\"training\",\n",
    "                                                batch_size=batch_size,\n",
    "                                                label_col=target_col_name,\n",
    "                                                data_loader_kwargs=dict(shuffle=True,\n",
    "                                                                        pin_memory=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.index.name=None\n"
     ]
    }
   ],
   "source": [
    "validation_dataloader = get_data_loader_from_dataset(dataset=dataset,\n",
    "                                                split=\"validation\",\n",
    "                                                batch_size=batch_size,\n",
    "                                                label_col=target_col_name,\n",
    "                                                data_loader_kwargs=dict(shuffle=True,\n",
    "                                                                        pin_memory=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "z_score_class\n",
       "0    0.718060\n",
       "2    0.154179\n",
       "1    0.127762\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[dataset.split == \"validation\", target_col_name].value_counts() / dataset[dataset.split == \"validation\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = dataset.loc[dataset.split == \"training\", target_col_name].value_counts() / dataset[dataset.split == \"training\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.48876634, 5.87348912, 6.32725694])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = (1/ weights).values\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.model.neural_network import BERTClassifier\n",
    "\n",
    "ckpt = None#\"lightning_logs/version_3/checkpoints/epoch=2-step=5469.ckpt\"\n",
    "if ckpt:\n",
    "    model = BERTClassifier.load_from_checkpoint(ckpt, deactivate_bert_learning=False)\n",
    "else:\n",
    "    model: nn.Module = BERTClassifier(bert_model_name=bert_model_name, \n",
    "                                    num_classes=3, \n",
    "                                    deactivate_bert_learning=True,\n",
    "                                    learning_rate=0.01,\n",
    "                                    class_weights=weights)\n",
    "\n",
    "trainer = pl.Trainer(num_sanity_val_steps=2,\n",
    "                     max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params\n",
      "------------------------------------------------------\n",
      "0 | train_accuracy | MulticlassAccuracy | 0     \n",
      "1 | val_accuracy   | MulticlassAccuracy | 0     \n",
      "2 | train_f1_score | MulticlassF1Score  | 0     \n",
      "3 | val_f1_score   | MulticlassF1Score  | 0     \n",
      "4 | bert           | BertModel          | 109 M \n",
      "5 | dropout        | Dropout            | 0     \n",
      "6 | ff_layer       | Sequential         | 15.9 K\n",
      "------------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "109 M     Non-trainable params\n",
      "109 M     Total params\n",
      "439.071   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  60%|██████    | 1101/1823 [02:01<01:19,  9.09it/s, v_num=3, train_loss (weighted)_step=1.090, train_loss_step=1.070, train_f1_score_step=0.500, train_accuracy_step=0.500, train_loss (weighted)_epoch=1.060, train_loss_epoch=0.962, train_f1_score_epoch=0.569, train_accuracy_epoch=0.581]"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, \n",
    "            train_dataloader, \n",
    "            validation_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2oQsYufL7R8M"
   },
   "outputs": [],
   "source": [
    "if google_colab:\n",
    "    from google.colab import runtime\n",
    "    runtime.unassign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a85t-TV27Uvs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

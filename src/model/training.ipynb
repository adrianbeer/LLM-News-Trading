{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6GUGkJ0V3lUT"
      },
      "outputs": [],
      "source": [
        "google_colab = False\n",
        "if google_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    cwd=\"/content/drive/MyDrive/NewsTrading/trading_bot\"\n",
        "    %cd /content/drive/MyDrive/NewsTrading/trading_bot\n",
        "    %pip install -r requirements_clean.txt\n",
        "    !git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "    !python rapidsai-csp-utils/colab/pip-install.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HZjfWVr73qUs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizerFast\n",
        "from src.model.data_loading import get_data_loader_from_dataset\n",
        "from src.config import config, MODEL_CONFIG\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Settings\n",
        "target_col_name = MODEL_CONFIG.target_col_name\n",
        "bert_model_name = MODEL_CONFIG.transformer_hugface_id\n",
        "batch_size = 4\n",
        "epochs = 1\n",
        "tokenizer = BertTokenizerFast.from_pretrained(bert_model_name)\n",
        "tracking_metrics = [accuracy_score, balanced_accuracy_score]\n",
        "learning_rate = 0.01 # 5e-5 (slow) for bert, 0.3 (fast) for new feed forward\n",
        "is_deactivated_bert_learning = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Current PyTorch version: 2.1.1+cu118 (should be 2.x+)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pt_version = torch.__version__\n",
        "print(f\"[INFO] Current PyTorch version: {pt_version} (should be 2.x+)\")\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pHvtsu8M4cJg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download dataset\n",
        "dataset = pd.read_parquet(config.data.merged).iloc[-20000:]\n",
        "dataset.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nthFIAsg4fh9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10819\n",
            "10413\n"
          ]
        }
      ],
      "source": [
        "# Filter out Stocks... TODO: put this into filter interface and make configurable in model_config\n",
        "dataset = dataset[\n",
        "    (dataset[\"unadj_open\"] >= 2) &          # penny stocks\n",
        "    (dataset[\"dollar_volume\"] >= 30_000)  # illiquid stocks TODO: this has look-ahead bias\n",
        "                  ]\n",
        "# TODO: Staleness has yet to be calculated\n",
        "if \"staleness\" in dataset.columns:\n",
        "    dataset = dataset[(dataset[\"staleness\"] <= 0.9)] # repeat news\n",
        "\n",
        "print(dataset.shape[0])\n",
        "dataset.dropna(inplace=True)\n",
        "print(dataset.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7289 samples in training set.\n",
            " 2082 samples in validation set.\n",
            " 1042 samples in testing set.\n"
          ]
        }
      ],
      "source": [
        "dataset: pd.DataFrame = MODEL_CONFIG.splitter.add_splits(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIkre90J4bGA",
        "outputId": "01fdbb7e-790a-4e26-af7f-eddd99489c0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset.index.name=None\n"
          ]
        }
      ],
      "source": [
        "train_dataloader = get_data_loader_from_dataset(dataset=dataset,\n",
        "                                                split=\"training\",\n",
        "                                                batch_size=batch_size,\n",
        "                                                label_col=target_col_name,\n",
        "                                                data_loader_kwargs=dict(shuffle=True,\n",
        "                                                                        pin_memory=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset.index.name=None\n"
          ]
        }
      ],
      "source": [
        "validation_dataloader = get_data_loader_from_dataset(dataset=dataset,\n",
        "                                                split=\"validation\",\n",
        "                                                batch_size=batch_size,\n",
        "                                                label_col=target_col_name,\n",
        "                                                data_loader_kwargs=dict(shuffle=True,\n",
        "                                                                        pin_memory=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir lighning_logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "z_score_class\n",
              "0    0.718060\n",
              "2    0.154179\n",
              "1    0.127762\n",
              "Name: count, dtype: float64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.loc[dataset.split == \"validation\", target_col_name].value_counts() / dataset[dataset.split == \"validation\"].shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "z_score_class\n",
              "0    0.671697\n",
              "1    0.170257\n",
              "2    0.158046\n",
              "Name: count, dtype: float64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.loc[dataset.split == \"training\", target_col_name].value_counts() / dataset[dataset.split == \"training\"].shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name     | Type       | Params\n",
            "----------------------------------------\n",
            "0 | bert     | BertModel  | 109 M \n",
            "1 | dropout  | Dropout    | 0     \n",
            "2 | ff_layer | Sequential | 15.9 K\n",
            "----------------------------------------\n",
            "15.9 K    Trainable params\n",
            "109 M     Non-trainable params\n",
            "109 M     Total params\n",
            "439.071   Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6:  14%|█▍        | 258/1823 [00:26<02:41,  9.67it/s, v_num=1]       "
          ]
        }
      ],
      "source": [
        "from src.model.neural_network import BERTClassifier\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "# model = BertClassifier.load_from_checkpoint(PATH)\n",
        "\n",
        "model: nn.Module = BERTClassifier(bert_model_name, 3, True)\n",
        "\n",
        "trainer = pl.Trainer(num_sanity_val_steps=2)\n",
        "\n",
        "trainer.fit(model, train_dataloader, validation_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oQsYufL7R8M"
      },
      "outputs": [],
      "source": [
        "if google_colab:\n",
        "    from google.colab import runtime\n",
        "    runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a85t-TV27Uvs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

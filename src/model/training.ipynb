{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GUGkJ0V3lUT"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "cwd=\"/content/drive/MyDrive/NewsTrading/trading_bot\"\n",
        "%cd /content/drive/MyDrive/NewsTrading/trading_bot\n",
        "%pip install -r requirements_clean.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KXpNmtC07Ek"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/pip-install.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZjfWVr73qUs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from transformers import BertTokenizerFast, get_linear_schedule_with_warmup\n",
        "from src.model.data_loading import get_data_loader_from_dataset\n",
        "from src.config import config, MODEL_CONFIG\n",
        "from src.model.neural_network import train\n",
        "\n",
        "# Settings\n",
        "bert_model_name = MODEL_CONFIG.transformer_hugface_id\n",
        "FROM_SCRATCH = True\n",
        "batch_size = 16\n",
        "epochs = 1\n",
        "tokenizer = BertTokenizerFast.from_pretrained(bert_model_name)\n",
        "loss_function = MODEL_CONFIG.loss_function\n",
        "learning_rate = 5e-5 # 5e-5 (slow) for bert, 0.3 (fast) for new feed forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pt_version = torch.__version__\n",
        "print(f\"[INFO] Current PyTorch version: {pt_version} (should be 2.x+)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHvtsu8M4cJg"
      },
      "outputs": [],
      "source": [
        "# Download dataset\n",
        "dataset = pd.read_parquet(config.data.merged)\n",
        "dataset.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nthFIAsg4fh9"
      },
      "outputs": [],
      "source": [
        "# Filter out Stocks... TODO: put this into filter interface and make configurable in model_config\n",
        "dataset = dataset[\n",
        "    (dataset[\"unadj_open\"] >= 2) &          # penny stocks\n",
        "    (dataset[\"dollar_volume\"] >= 30_000) &  # illiquid stocks TODO: this has look-ahead bias\n",
        "    (dataset[\"staleness\"] <= 0.9)           # repeat news\n",
        "                  ]\n",
        "print(dataset.shape[0])\n",
        "dataset.dropna(inplace=True)\n",
        "print(dataset.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset: pd.DataFrame = MODEL_CONFIG.splitter.add_splits(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIkre90J4bGA",
        "outputId": "01fdbb7e-790a-4e26-af7f-eddd99489c0b"
      },
      "outputs": [],
      "source": [
        "train_dataloader = get_data_loader_from_dataset(dataset=dataset,\n",
        "                                                split=\"training\",\n",
        "                                                tokenizer=tokenizer,\n",
        "                                                batch_size=batch_size,\n",
        "                                                data_loader_kwargs=dict(shuffle=True,\n",
        "                                                                        pin_memory=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_dataloader = get_data_loader_from_dataset(dataset=dataset,\n",
        "                                                split=\"validation\",\n",
        "                                                tokenizer=tokenizer,\n",
        "                                                batch_size=batch_size,\n",
        "                                                data_loader_kwargs=dict(shuffle=True,\n",
        "                                                                        pin_memory=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i-dNsG_3hN5",
        "outputId": "bfa57c74-5913-4404-b8a4-3bca24d9262f"
      },
      "outputs": [],
      "source": [
        "model: nn.Module = MODEL_CONFIG.BertClass(bert_model_name)\n",
        "if not FROM_SCRATCH:\n",
        "    model.load_state_dict(torch.load(\"data/model\"))\n",
        "    \n",
        "model.deactivate_learning_for_layer(model.bert)\n",
        "\n",
        "# .compile currently isn't supported for Windows\n",
        "# model = torch.compile(model)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(\"Using GPU.\")\n",
        "    else:\n",
        "        print(\"No GPU available, using the CPU instead.\")\n",
        "        device = torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Optimizer, scheduler and loss function\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
        "\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0,\n",
        "                                                num_training_steps=total_steps)\n",
        "\n",
        "    # Training\n",
        "    model, training_stats = train(model,\n",
        "                                  optimizer,\n",
        "                                  scheduler,\n",
        "                                  loss_function,\n",
        "                                  epochs,\n",
        "                                  train_dataloader,\n",
        "                                  validation_dataloader,\n",
        "                                  device,\n",
        "                                  clip_value=2)\n",
        "\n",
        "    df_stats = pd.DataFrame(data=training_stats)\n",
        "    print(df_stats)\n",
        "\n",
        "    # Store Model\n",
        "    torch.save(model.state_dict(), \"data/model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oQsYufL7R8M"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a85t-TV27Uvs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

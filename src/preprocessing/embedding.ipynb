{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizerFast\n",
    "from src.model.data_loading import embed_inputs\n",
    "from src.config import config, MODEL_CONFIG\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial\n",
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_input(text, tokenizer):\n",
    "    # Truncation = True as bert can only take inputs of max 512 tokens.\n",
    "    # return_tensors = \"pt\" makes the funciton return PyTorch tensors\n",
    "    # tokenizer.encode_plus specifically returns a dictionary of values instead of just a list of values\n",
    "    encoding = tokenizer(\n",
    "        text, \n",
    "        add_special_tokens = True, \n",
    "        truncation = True, \n",
    "        padding = \"max_length\", \n",
    "        max_length = 512,\n",
    "        return_attention_mask = True, \n",
    "        return_tensors = \"pt\"\n",
    "    )\n",
    "    # input_ids: mapping the words to tokens\n",
    "    # attention masks: idicates if index is word or padding\n",
    "    input_ids = encoding['input_ids']\n",
    "    attention_masks = encoding['attention_mask']\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "\n",
    "@timing\n",
    "def embed_inputs(texts: list, tokenizer) -> tuple[Tensor, Tensor]:\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    pool_obj = ThreadPoolExecutor(max_workers=os.cpu_count())\n",
    "    ans = pool_obj.map(partial(embed_input, tokenizer=tokenizer), texts)\n",
    "    input_ids, attention_masks = list(zip(*ans))\n",
    "\n",
    "    input_ids: Tensor = torch.cat(input_ids, dim=0)\n",
    "    attention_masks: Tensor = torch.cat(attention_masks, dim=0)\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_and_labels(dat: pd.DataFrame, \n",
    "                        text_col: str = None,\n",
    "                        label_col: str = None) -> tuple[List, List]:\n",
    "    if not text_col:\n",
    "        text_col = MODEL_CONFIG.input_col_name\n",
    "    if not label_col:\n",
    "        label_col = MODEL_CONFIG.target_col_name\n",
    "    texts = dat.loc[:, text_col].tolist()\n",
    "    labels = dat.loc[:, label_col].tolist()\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoding_length = 512\n",
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_CONFIG.transformer_hugface_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_parquet(config.data.benzinga.cleaned)\n",
    "# Dummy column\n",
    "dataset[\"text_length\"] = dataset[\"parsed_body\"].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels = get_text_and_labels(dat=dataset, \n",
    "                                    split=None, \n",
    "                                    text_col=\"parsed_body\", \n",
    "                                    label_col=\"text_length\")\n",
    "input_ids, masks = embed_inputs(texts, \n",
    "                             tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func:'embed_inputs' took: 14.4095 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Meine Ablage\\NewsTrading\\trading_bot\\src\\model\\data_loading.py:36: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "g:\\Meine Ablage\\NewsTrading\\trading_bot\\src\\model\\data_loading.py:37: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assert taht the max length of input_ids is 512 -> where is this configured??\n",
    "np.max([len(x) for x in input_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs to be done this way in order to store lists inside a pd.DataFrame cell\n",
    "input_ids = pd.Series(index=dataset.index, data=list(input_ids))\n",
    "masks = pd.Series(index=dataset.index, data=list(masks))\n",
    "dataset[\"input_id\"] = input_ids\n",
    "dataset[\"mask\"] = masks\n",
    "dataset.to_parquet(config.data.benzinga.cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding_matrix = np.ndarray(shape=(2*len(input_ids)+1, max_encoding_length))\n",
    "# encoding_matrix[:, 0] = dataset.index\n",
    "# encoding_matrix[:, 1:(max_encoding_length+1)] == input_ids\n",
    "# encoding_matrix[:, (max_encoding_length+1):] == masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(file=encoding_matrix_path, arr=encoding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_encoding(encoding_matrix_path: str):\n",
    "#     encoding_matrix = np.load(file=encoding_matrix_path, arr=encoding_matrix)\n",
    "#     index = encoding_matrix[:, 0]\n",
    "#     input_ids = encoding_matrix[:, 1:(max_encoding_length+1)]\n",
    "#     masks = encoding_matrix[:, (max_encoding_length+1):]\n",
    "#     return index, input_ids, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

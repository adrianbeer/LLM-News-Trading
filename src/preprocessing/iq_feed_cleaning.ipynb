{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import plotly.express as px\n",
    "import pytz\n",
    "eastern = pytz.timezone('US/Eastern')\n",
    "import yfinance \n",
    "\n",
    "from dotmap import DotMap\n",
    "import yaml\n",
    "config = DotMap(yaml.safe_load(open(\"src/config.yaml\")), _dynamic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_trading_hours(df, time_column):\n",
    "    T = df[time_column].dt\n",
    "    min_mask = (T.hour >= 10) | ((T.hour == 9) & (T.minute >= 31))\n",
    "    max_mask = (T.hour < 16) | ((T.hour == 16) & (T.minute <= 1))\n",
    "    return df.loc[min_mask & max_mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_iq_feed_prices(prices: pd.DataFrame) -> pd.DataFrame: \n",
    "    if \"time\" in prices.columns:\n",
    "        # Intra-day data\n",
    "        prices.loc[:, \"time\"] = prices.loc[:, \"time\"].dt.tz_localize(None)\n",
    "        prices.loc[:, \"time\"] = prices.loc[:, \"time\"].dt.tz_localize(eastern)\n",
    "        prices.drop_duplicates(keep=\"first\", inplace=True)\n",
    "        prices.dropna(inplace=True)\n",
    "        \n",
    "        prices = filter_trading_hours(df=prices, time_column=\"time\")\n",
    "\n",
    "        # Deals with duplicate rows which occurr when not all the digits for volume are \n",
    "        # correctly entered, but only the first 1-3. So keep the largest.\n",
    "        prices = prices.sort_values([\"time\", \"volume\"], ascending=[True, False])\n",
    "        prices = prices.drop_duplicates(subset=[\"time\"], keep=\"first\")\n",
    "\n",
    "        prices.set_index(\"time\", inplace=True)\n",
    "        prices.sort_index(ascending=True, inplace=True)\n",
    "        assert prices.index.is_unique\n",
    "    else:\n",
    "        # Daily data\n",
    "        prices.dropna(inplace=True)\n",
    "        prices[\"date\"] = pd.to_datetime(prices.date)\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = [f for f in listdir(config.data.iqfeed.minute.raw) if isfile(join(config.data.iqfeed.minute.raw, f))]\n",
    "tickers = [x.split(\"_\")[0] for x in onlyfiles]\n",
    "ticker = \"MBGH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices: pd.DataFrame = preprocess_iq_feed_prices(pd.read_parquet(path=f\"{config.data.iqfeed.minute.raw}/{ticker}_1min.parquet\", \n",
    "                                                                 columns=[\"time\", \"close\", \"open\", \"volume\"]))\n",
    "prices_daily: pd.DataFrame = preprocess_iq_feed_prices(pd.read_parquet(path=f\"{config.data.iqfeed.minute.raw}/daily/{ticker}_daily.parquet\", \n",
    "                                                                       columns=[\"date\", \"close\", \"open\", \"volume\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df = yfinance.download(ticker, period=\"15y\",actions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust for Splits and Dividends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_closes = prices.loc[(prices.index.hour == 16) & (prices.index.minute == 1), \"open\"]\n",
    "# Converts datetime[us] to datetime[ns] and floors to daily frequency.\n",
    "intra_closes.index = pd.to_datetime(intra_closes.index.date)\n",
    "intra_closes.index.name = \"date\"\n",
    "intra_closes.name = \"close_intra\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(intra_closes, prices_daily[[\"date\", \"close\"]], left_on=\"date\", right_on=\"date\", suffixes=(\"_intra\", \"_eod\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.sort_index(ascending=False)\n",
    "merged[\"split_ratio\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.rename(columns=dict(close=\"close_eod\"), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate splits (IQFeed EOD isplit adjusted, but not dividend adjusted)\n",
    "# To adjust, we go backwrds in time. \n",
    "# When a split has occurred the close will be the first price that is influenced in the historical adjusted time series.\n",
    "# Assuming the split/dividend has occurred overnight.\n",
    "for i in range(len(merged.index)):\n",
    "    row = merged.index[i]\n",
    "    \n",
    "    split_ratios = merged.iloc[i:i+5][\"close_eod\"] / merged.iloc[i:i+5][\"close_intra\"]\n",
    "    \n",
    "    # All split ratios are larger than 1% => persistent discrepancy\n",
    "    if min(np.abs(split_ratios - 1)) >= 0.01:\n",
    "        split_ratio = merged.loc[row, \"close_eod\"] / merged.loc[row, \"close_intra\"]\n",
    "        merged.loc[row:, \"close_intra\"]  = (merged.loc[row:, \"close_intra\"] * split_ratio)\n",
    "        merged.loc[row, \"split_ratio\"]  = split_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged.date.dt.tz_localize(\"US/Eastern\")\n",
    "_merged_intra_idx = X  + pd.DateOffset(hours=16, minutes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices[\"split_ratio\"] = 1\n",
    "prices.loc[_merged_intra_idx, \"split_ratio\"] = merged[\"split_ratio\"]\n",
    "prices[\"cum_split_ratio\"] = np.cumprod(prices[\"split_ratio\"][::-1])[::-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_ratio < 1 => price goes down\n",
    "# stocks dont trade in fractions of a penny, hence we need to round to 2 decimals\n",
    "prices[[\"open\", \"close\"]] = (prices[[\"open\", \"close\"]] * prices[\"cum_split_ratio\"])\n",
    "\n",
    "# split_ratio < 1 => volume goes up, since price goes down and pricevolume has to stay the same \n",
    "# (volume denotes number of stocks traded)\n",
    "prices[\"volume\"] = prices[\"volume\"] / prices[\"cum_split_ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#px.line(merged[[\"close_intra\", \"close_eod\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check quality looking at the amount of splits/dividends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Download yfinance split data and check if there is a difference between the calculated splits/dividends\n",
    "# IMPORTANT !!!!!!!!!!\n",
    "# In yahoo finance the `Close` is adj. for splits and the `Adj. Close` for splits and dividends\n",
    "# Dividends on Yahoo Finance are adjusted for splits!\n",
    "import yfinance\n",
    "\n",
    "df=yfinance.download(ticker, period=\"10y\",actions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"split_ratio\"] = 1\n",
    "split_mask = df[\"Stock Splits\"] > 0\n",
    "# TODO Do we have to apply the split the next day or the current day?\n",
    "df.loc[split_mask, \"split_ratio\"] = 1 / df.loc[split_mask, \"Stock Splits\"] \n",
    "\n",
    "#df[\"Dividends\"] = df[\"Dividends\"].shift(-1, fill_value=0)\n",
    "dividend_mask = (df[\"Dividends\"] > 0)\n",
    "df.loc[dividend_mask, \"split_ratio\"] = 1 + df.loc[dividend_mask, \"Dividends\"] / df.loc[dividend_mask, \"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"split_ratio\"] = df.loc[:, \"split_ratio\"].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check quality looking at the difference between intra_day adj open and eod adj open.\n",
    "# This difference should be smaller than the split_ratio for all days where the split_ratio is not 1\n",
    "# This difference should also be smaller in general than our threshold for splits (1%?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once this has been checked and intraday data consistency/continuity is assured we could\n",
    "# Replace all the closes and opens from the intra day data set with those of the eod data set.\n",
    "# However this leads to problems, if we calculate wrong a single split event.\n",
    "# If we don't do this replacement only one bday is affected (split day). \n",
    "# If we do the replacement multiple days will be affected by the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save adjusted files to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkovyr-oc4-K"
   },
   "source": [
    "# Benzinga-Nachrichten-Verarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2A8GOctQmMfj"
   },
   "source": [
    "## Setup up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxfEWak8MNGE"
   },
   "source": [
    "### Cluster spin up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8pmVviAjMTaQ"
   },
   "outputs": [],
   "source": [
    "use_colab = False\n",
    "if use_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    cwd=\"/content/drive/MyDrive/NewsTrading/trading_bot\"\n",
    "    %cd /content/drive/MyDrive/NewsTrading/trading_bot\n",
    "    %pip install -r requirements_clean.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gxfs_work/cau/sunms534/trading_bot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /gxfs_work/cau/sunms534/trading_bot/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "zj0QodzRMNGE",
    "outputId": "88876701-df20-40bc-aab1-3dec09411b9a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from src.config import config \n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
    "\n",
    "from src.utils.dataframes import parallelize_dataframe, block_apply_factory\n",
    "from src.preprocessing.news_parser import infer_author, filter_body, body_formatter\n",
    "\n",
    "pd.set_option(\n",
    "    'display.max_colwidth', 2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRqa0EPy_lpx"
   },
   "source": [
    "## Grobes HTML-Parsing\n",
    "Als erstes müssen wir die HTML-Dokumente zu normalem Text umwandeln, ansonsten sind die Text-Zellen zu groß und führen zu Problemen mit PyArrow/Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_body_formatter(s: pd.Series):\n",
    "    return s.progress_apply(body_formatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOM after starting second loop... something isn't being properly being garbage collected... maybe the child processes of multiprocessing in parallelize_dataframe?\n",
    "%%time\n",
    "for year in range(2023, 2024):\n",
    "    print(f\"{year}\")\n",
    "    df = pd.read_parquet(config.data.benzinga.raw + f\"/story_df_raw_{year}.parquet\")\n",
    "    df[\"html_body\"] = parallelize_dataframe(df[\"html_body\"], block_apply_factory(body_formatter), n_cores=os.cpu_count())\n",
    "    df = df.rename(columns={\"html_body\":\"body\"})\n",
    "    df.to_parquet(config.data.benzinga.raw_html_parsed + f\"/story_df_html_parsed{year}.parquet\")\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFnIFQW2Nag7"
   },
   "source": [
    "## Author-Inferenz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHFpynyiq3O4"
   },
   "outputs": [],
   "source": [
    "ddf = pd.read_parquet(config.data.benzinga.raw_html_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.350560428574681"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.memory_usage(deep=True).sum() / 1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ylwarwpXLegE"
   },
   "outputs": [],
   "source": [
    "# Remove rows for which noo stock ticker is recorded\n",
    "ddf = ddf[ddf.stocks != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eu1EhTqrVpBG"
   },
   "source": [
    "Untersuche als nächstes die Behauptung, dass **PRNewswire** und **Businesswire** den gesamten Markt für Pressemeldungen in den USA kontrollieren. Wenn dem so ist, und sie nicht noch weitere, unwichtige Meldungen veröffentlichen, dann können wir einfach die Newsartikel nach diesen Autoren filtern und uns viel Arbeit ersparen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "D5mO091MfO6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2086193/2086193 [02:11<00:00, 15847.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 7s, sys: 3.77 s, total: 2min 11s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ddf[\"inferred_author\"] = None\n",
    "ddf[\"inferred_author\"] = ddf.body.progress_apply(infer_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NTcPjnU0VZZu"
   },
   "outputs": [],
   "source": [
    "# value_counts for authors\n",
    "auhtor_value_counts = pd.concat([ddf.author.value_counts().head(10), ddf.inferred_author.value_counts().head(10)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UNesN9jX1IP0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Benzinga</th>\n",
       "      <td>1061214</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRNewswire</th>\n",
       "      <td>305720</td>\n",
       "      <td>586783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Globe Newswire</th>\n",
       "      <td>293466</td>\n",
       "      <td>476243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Wire</th>\n",
       "      <td>268561</td>\n",
       "      <td>295121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Newsfile</th>\n",
       "      <td>70877</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACCESSWIRE</th>\n",
       "      <td>62615</td>\n",
       "      <td>81036.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AB Digital, Inc.</th>\n",
       "      <td>9936</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WebWire</th>\n",
       "      <td>6404</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRWeb</th>\n",
       "      <td>2617</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>News Direct</th>\n",
       "      <td>2080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count     count\n",
       "Benzinga          1061214       NaN\n",
       "PRNewswire         305720  586783.0\n",
       "Globe Newswire     293466  476243.0\n",
       "Business Wire      268561  295121.0\n",
       "Newsfile            70877       NaN\n",
       "ACCESSWIRE          62615   81036.0\n",
       "AB Digital, Inc.     9936       NaN\n",
       "WebWire              6404       NaN\n",
       "PRWeb                2617       NaN\n",
       "News Direct          2080       NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auhtor_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TKT6tusBp13y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count         NaN\n",
       "count   -644307.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auhtor_value_counts.sum().diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wk6p6woeqJqP"
   },
   "source": [
    "Ungefähr 650k Nachrichten werden ausgelassen, wenn nur die vier Hauptvertreiber von Pressemeldungen berücksichtigt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8X8rHo-CsDCQ"
   },
   "outputs": [],
   "source": [
    "ddf = ddf[~ddf.inferred_author.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xHvzym8sFcX_"
   },
   "outputs": [],
   "source": [
    "ddf[\"inferred_author\"] = ddf[\"inferred_author\"].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KsEmViTzNvgs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inferred_author\n",
       "PRNewswire        586783\n",
       "Globe Newswire    476243\n",
       "Business Wire     295121\n",
       "ACCESSWIRE         81036\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.inferred_author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zfNNyD_31sly"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1439183"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.inferred_author.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pmMI9DsEhrn2"
   },
   "outputs": [],
   "source": [
    "ddf = ddf.drop(columns=[\"author\"]).rename(columns={\"inferred_author\":\"author\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "CLdnwdyxNFiH"
   },
   "outputs": [],
   "source": [
    "# Contains 100k rows\n",
    "earnings_ddf = ddf[ddf.channels.apply(lambda x: \"Earnings\" in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "A-zs5SSiVbyp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "Globe Newswire    44651\n",
       "PRNewswire        31382\n",
       "ACCESSWIRE        16429\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value counts for authors of earnings reports (contrast to value counts of all news articles)\n",
    "earnings_ddf.author.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dVD6j-G9nie"
   },
   "source": [
    "Hier sehen wir, dass es keine einzige Pressemeldung von **Business Wire** gibt, die mit *Earnings* gekennzeichnet sind. Trotzdem gibt es relevante *Earnings* reports von Business Wire. Dies habe ich kurz verifiziert..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jafqZ87tXDKn"
   },
   "source": [
    "Wie viele Nachrichten bleiben, wenn wir auf relevante Ticker filtern? Wir wollen nicht(!) - so ist es momentan - auf die momentane Russell 3k-Zusammensetzung filtern, denn wir wollen auch ungelistete bzw. ehemalige Russell-Aktien beachten.\n",
    "\n",
    "\n",
    "**1. Full-Name-Discovery:**\n",
    "\n",
    "Herausfinden des vollen Namens des Unternehmens für jeden Ticker, damit 1. der Text richtig geparst werden kann und 2. damit wir einen Anhaltspunkt für das Ticker-Grouping haben.\n",
    "\n",
    "\n",
    "**2. Ticker-Filtering:**\n",
    "\n",
    "Alle Ticker herausfiltern, die wir nicht brauchen. Wenn wir aber ein großes Aktienuniversum (mit inzwischen ungelisteten Aktien) benutzen, werden wir fast alle Nachrichten behalten können. Allerdings lassen sich so Fehlerhafte Nachrichten/Ticker etc. herausfiltern.\n",
    "\n",
    "\n",
    "**3. Ticker-Grouping:**\n",
    "\n",
    "Was machen wir, wenn wir mehrerer Aktiengattungen für ein Unternehmen haben? Z.B. Vorzugs- und Stammaktien. Wir können i.A. die Stammaktie nehmen, da diese normalerweise ein höheres Handelsvolumen aufweist. D.h. wir bilden alle Ticker der Benzinga-Nachrichten auf den Ticker der Stammaktie ab.\n",
    "\n",
    "\n",
    "**4. Firmennamen-Nachrichtenkörper-Verifikation:**\n",
    "\n",
    "Da Ticker wiederverwendet werden können bzw. sich verändern können wollen wir sicherstellen, dass der Unternehmensname im Nachrichtenkörper vorkommt. Bzw. generell ist das eine gute Datensäuberungs-Maßnahme. Einerseits verhindern wir,\n",
    "dass später Aktienkurse einer falschen Aktie zugeordnet wird. Andererseits werden dadurch evtl. auch weniger seriöse Nachrichten herausgefiltert, die nicht\n",
    "die Kontaktadresszeile des Unternehmens am Ende besitzen, in dem der vollständige Unternehmensname vorkommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = pd.read_parquet(config.data.shared.ticker_name_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "70POMUC-PN-n"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1019998/1019998 [00:08<00:00, 117651.29it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1019998/1019998 [00:08<00:00, 116900.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es verbleiben 1019998 Nachrichten, für die wir den Ticker zu einem Firmennamen aufgelösen konnten.\n"
     ]
    }
   ],
   "source": [
    "ddf = ddf[ddf.stocks.isin(mapper.index.to_list())]\n",
    "ddf[\"company_name\"] = ddf.stocks.progress_map(lambda x: mapper.company_names.loc[x]).astype(str)\n",
    "ddf[\"short_name\"] = ddf.stocks.progress_map(lambda x: mapper.short_name.loc[x]).astype(str)\n",
    "print(f\"Es verbleiben {ddf.shape[0]} Nachrichten, für die wir den Ticker zu einem Firmennamen aufgelösen konnten.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74407                              Rent the Runway, Inc.\n",
       "74409                             WW International, Inc.\n",
       "74416                        JetBlue Airways Corporation\n",
       "74443       iShares International Developed Property ETF\n",
       "74467                             The Ensign Group, Inc.\n",
       "                                ...                     \n",
       "34016296                                     Canaan Inc.\n",
       "34016421                               Kirby Corporation\n",
       "34016619                 Chindata Group Holdings Limited\n",
       "34016667              Orbital Infrastructure Group, Inc.\n",
       "34016713                               ImmunityBio, Inc.\n",
       "Name: company_name, Length: 1019998, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.company_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Xw1JSiI_0JH"
   },
   "source": [
    "### Duplikate Entfernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "cEzrJqEN_yuJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_before=1019998, samples_after=1017103\n",
      "CPU times: user 11.2 s, sys: 1.95 s, total: 13.1 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "samples_before = ddf.shape[0]\n",
    "ddf = ddf.drop_duplicates()\n",
    "samples_after = ddf.shape[0]\n",
    "print(f\"{samples_before=}, {samples_after=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3F3dOc35YN8k"
   },
   "source": [
    "### Firmennamen-Nachrichtenkörper-Verifikation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_company_name_in_body(df):\n",
    "    return df.apply(lambda x: bool(re.search(x[\"short_name\"],\n",
    "                                             x.title + x[\"body\"].replace(\"( )*\\n( )*\", \" \"),\n",
    "                                             re.IGNORECASE)),\n",
    "                    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cores=32, df.shape=(1017103, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "parallelize_data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:09<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Around 11383 stocks before filtering and 9939 after\n",
      "CPU times: user 2.98 s, sys: 8.88 s, total: 11.9 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mask = parallelize_dataframe(ddf, verify_company_name_in_body, n_cores=os.cpu_count())\n",
    "\n",
    "print(f\"Around {len(ddf.stocks.unique())} stocks before filtering and {len(ddf[mask].stocks.unique())} after\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "oNAFvvVmmWm2"
   },
   "outputs": [],
   "source": [
    "# Filter out faulty news\n",
    "ddf = ddf[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bshj1secWQ3P"
   },
   "source": [
    "Bis zu 5k Nachrichten pro Firma, z.B. AT&T, was in 13 Jahren ca. einer Nachricht pro Tag entspricht. Wir wollen nicht das eine Firma mit vielen Junk-Nachrichten das Modell dominiert. Wobei das Modell hoffentlich dann auch die Junk-Nachrichten als solche erkennt und ignoriert. Eher wichtig noch einen `staleness`-Faktor, also wie ähnlich die Nachricht zu Vorhergegangenen ist (i.e. Nachrichten desselben Tages oder derselben Woche).\n",
    "\n",
    "Kategorisieren von Nachrichten (mit Text2Topic, wie Salbrechter?) und eliminieren von Business/Strategic etc.\n",
    "Im Falle von Text2Topic, versuche Estimates des Unternehmens von Dritten zu unterscheiden.\n",
    "\n",
    "Wichtig!!! Unterscheide zwischen LERN-Phase und PRODUKTIONS-Phase.\n",
    "Wir können z.B. CLS-Token in der Produktions-Phase vergleichen, in der Lern-Phase aber noch nicht.\n",
    "\n",
    "Text2Vec -> Business category evtl. entfernen-> Intrastock variance average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make reduced ticker name mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dK5naDT8t1Ap"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 11383 to 9939 tickers (reduced)\n"
     ]
    }
   ],
   "source": [
    "ticker_name_mapper = pd.read_parquet(config.data.shared.ticker_name_mapper)\n",
    "\n",
    "ticker_name_mapper_reduced = ddf[[\"stocks\", \"company_name\", \"short_name\"]].drop_duplicates(keep=\"first\")\n",
    "\n",
    "ticker_name_mapper_reduced.to_parquet(config.data.shared.ticker_name_mapper_reduced)\n",
    "\n",
    "print(f\"From {ticker_name_mapper.shape[0]} to {ticker_name_mapper_reduced.shape[0]} tickers (reduced)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRABrPVOcaa9"
   },
   "source": [
    "## Parsing News Bodies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "qubEijBxMNGt"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b5ac7b1d0e4a90a7f5db325e20b15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/878922 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.utils.time import convert_timezone\n",
    "ddf[\"time\"] = ddf[\"time\"].progress_map(lambda x: convert_timezone(pd.to_datetime(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ddf#.iloc[:10000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGlOJPEvFxuP",
    "outputId": "2e7b693a-72c0-46d8-e93c-11f6feb29d09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cores=32, df.shape=(878922, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "parallelize_data:   0%|                                                                                                                                                                     | 0/32 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ddf[\"parsed_body\"] = parallelize_dataframe(sample, block_apply_factory(filter_body), n_cores=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.to_parquet(config.data.benzinga.cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.preprocessing.news_parser import remove_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.company_name.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[[\"body\", \"parsed_body\"]].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ihzi516YMNGv"
   },
   "source": [
    "## Filtern von Newstiteln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdbc2yRqMNGv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1DIhhqZMNGv"
   },
   "source": [
    "## Voranstellen von gefilterten Newstiteln an Nachrichtenkörper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFEujkJ-MNGw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaK5pLz4mRHF"
   },
   "source": [
    "## Durschnittlichen Tokenlänge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timedeltas zwischen Nachrichtenmeldungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.read_parquet(config.data.benzinga.cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = ddf.sort_values(\"time\")\n",
    "tmp = ddf[[\"time\", \"stocks\"]]\n",
    "#### Adding timedeltas to the data frame\n",
    "news_timedeltas = tmp.groupby(\"stocks\").transform(lambda x: x.diff())\n",
    "ddf.loc[:, \"timedelta\"] = news_timedeltas.time.fillna(pd.Timedelta(days=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_timedeltas = ddf.timedelta\n",
    "news_timedeltas.iloc[0].components\n",
    "timedelta_in_minutes = news_timedeltas.apply(lambda x: x.total_seconds() / 60)\n",
    "px.histogram(timedelta_in_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VG5rnSiNpWVN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mc6lpRCpfVT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

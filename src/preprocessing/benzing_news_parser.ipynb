{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkovyr-oc4-K"
   },
   "source": [
    "# Benzinga-Nachrichten-Verarbeitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2A8GOctQmMfj"
   },
   "source": [
    "## Setup up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxfEWak8MNGE"
   },
   "source": [
    "### Cluster spin up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8pmVviAjMTaQ"
   },
   "outputs": [],
   "source": [
    "use_colab = False\n",
    "if use_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    cwd=\"/content/drive/MyDrive/NewsTrading/trading_bot\"\n",
    "    %cd /content/drive/MyDrive/NewsTrading/trading_bot\n",
    "    %pip install -r requirements_clean.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gxfs_work/cau/sunms534/trading_bot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /gxfs_work/cau/sunms534/trading_bot/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "zj0QodzRMNGE",
    "outputId": "88876701-df20-40bc-aab1-3dec09411b9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:torchaudio._extension:Failed to initialize sox extension\n",
      "Traceback (most recent call last):\n",
      "  File \"/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torchaudio/_extension/__init__.py\", line 60, in <module>\n",
      "    _init_sox()\n",
      "  File \"/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torchaudio/_extension/utils.py\", line 70, in _init_sox\n",
      "    _load_lib(\"libtorchaudio_sox\")\n",
      "  File \"/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torchaudio/_extension/utils.py\", line 64, in _load_lib\n",
      "    torch.ops.load_library(path)\n",
      "  File \"/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torch/_ops.py\", line 852, in load_library\n",
      "    ctypes.CDLL(path)\n",
      "  File \"/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: libsox.so: cannot open shared object file: No such file or directory\n",
      "DEBUG:torchaudio._extension.utils:Attempting to load FFmpeg version 6.\n",
      "DEBUG:torchaudio._extension.utils:Failed to load FFmpeg 6 extension.\n",
      "Traceback (most recent call last):\n",
      "  File \"/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torchaudio/_extension/utils.py\", line 128, in _find_ffmpeg_extension\n",
      "    return _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torchaudio/_extension/utils.py\", line 113, in _find_versionsed_ffmpeg_extension\n",
      "    _try_access_avutil(ffmpeg_ver)\n",
      "  File \"/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torchaudio/_extension/utils.py\", line 89, in _try_access_avutil\n",
      "    torchaudio.lib._torchaudio.find_avutil(libavutil)\n",
      "RuntimeError: Error in dlopen: libavutil.so.58: cannot open shared object file: No such file or directory\n",
      "Exception raised from DynamicLibrary at /opt/conda/conda-bld/pytorch_1702400440653/work/aten/src/ATen/DynamicLibrary.cpp:38 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x14e34fe44617 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0xc669fc (0x14e39dd809fc in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: torchaudio::find_avutil(char const*) + 0x1a (0x14e32dce24ca in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torchaudio/lib/libtorchaudio.so)\n",
      "frame #3: <unknown function> + 0x7f8e (0x14e32dc91f8e in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torchaudio/lib/_torchaudio.so)\n",
      "frame #4: <unknown function> + 0x12847 (0x14e32dc9c847 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torchaudio/lib/_torchaudio.so)\n",
      "frame #5: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x528187]\n",
      "frame #6: _PyObject_MakeTpCall + 0x27c (0x503a0c in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #7: _PyEval_EvalFrameDefault + 0x6a3 (0x510f33 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #8: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5cb55a]\n",
      "frame #9: PyEval_EvalCode + 0x9f (0x5cac2f in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #10: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5e43d3]\n",
      "frame #11: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x51e1c7]\n",
      "frame #12: _PyEval_EvalFrameDefault + 0x9025 (0x5198b5 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #13: _PyFunction_Vectorcall + 0x173 (0x538733 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #14: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x526b73]\n",
      "frame #15: PyObject_CallMethodObjArgs + 0x11c (0x55600c in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #16: PyImport_ImportModuleLevelObject + 0x757 (0x555b57 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #17: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x56a2d0]\n",
      "frame #18: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x51e1c7]\n",
      "frame #19: _PyEval_EvalFrameDefault + 0x9025 (0x5198b5 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #20: _PyFunction_Vectorcall + 0x173 (0x538733 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #21: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x526b73]\n",
      "frame #22: PyObject_CallMethodObjArgs + 0x11c (0x55600c in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #23: PyImport_ImportModuleLevelObject + 0x971 (0x555d71 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #24: _PyEval_EvalFrameDefault + 0x5f73 (0x516803 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #25: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5cb55a]\n",
      "frame #26: PyEval_EvalCode + 0x9f (0x5cac2f in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #27: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5e43d3]\n",
      "frame #28: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x51e1c7]\n",
      "frame #29: _PyEval_EvalFrameDefault + 0x9025 (0x5198b5 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #30: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5cb55a]\n",
      "frame #31: PyEval_EvalCode + 0x9f (0x5cac2f in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #32: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5e43d3]\n",
      "frame #33: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x51e1c7]\n",
      "frame #34: _PyEval_EvalFrameDefault + 0x9025 (0x5198b5 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #35: _PyFunction_Vectorcall + 0x173 (0x538733 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #36: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x526b73]\n",
      "frame #37: PyObject_CallMethodObjArgs + 0x11c (0x55600c in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #38: PyImport_ImportModuleLevelObject + 0x757 (0x555b57 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #39: _PyEval_EvalFrameDefault + 0x5f73 (0x516803 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #40: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5cb55a]\n",
      "frame #41: PyEval_EvalCode + 0x9f (0x5cac2f in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #42: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5e43d3]\n",
      "frame #43: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x51e1c7]\n",
      "frame #44: _PyEval_EvalFrameDefault + 0x9025 (0x5198b5 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #45: _PyFunction_Vectorcall + 0x173 (0x538733 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #46: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x526b73]\n",
      "frame #47: PyObject_CallMethodObjArgs + 0x11c (0x55600c in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #48: PyImport_ImportModuleLevelObject + 0x757 (0x555b57 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #49: _PyEval_EvalFrameDefault + 0x5f73 (0x516803 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #50: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5cb55a]\n",
      "frame #51: PyEval_EvalCode + 0x9f (0x5cac2f in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #52: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5e43d3]\n",
      "frame #53: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x51e1c7]\n",
      "frame #54: _PyEval_EvalFrameDefault + 0x9025 (0x5198b5 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #55: _PyFunction_Vectorcall + 0x173 (0x538733 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #56: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x526b73]\n",
      "frame #57: PyObject_CallMethodObjArgs + 0x11c (0x55600c in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #58: PyImport_ImportModuleLevelObject + 0x757 (0x555b57 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #59: _PyEval_EvalFrameDefault + 0x5f73 (0x516803 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #60: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5cb55a]\n",
      "frame #61: PyEval_EvalCode + 0x9f (0x5cac2f in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #62: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5e43d3]\n",
      "frame #63: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x51e1c7]\n",
      "\n",
      "DEBUG:torchaudio._extension.utils:Attempting to load FFmpeg version 5.\n",
      "DEBUG:torchaudio._extension.utils:Failed to load FFmpeg 5 extension.\n",
      "Traceback (most recent call last):\n",
      "  File \"/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torchaudio/_extension/utils.py\", line 128, in _find_ffmpeg_extension\n",
      "    return _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torchaudio/_extension/utils.py\", line 113, in _find_versionsed_ffmpeg_extension\n",
      "    _try_access_avutil(ffmpeg_ver)\n",
      "  File \"/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torchaudio/_extension/utils.py\", line 89, in _try_access_avutil\n",
      "    torchaudio.lib._torchaudio.find_avutil(libavutil)\n",
      "RuntimeError: Error in dlopen: libavutil.so.57: cannot open shared object file: No such file or directory\n",
      "Exception raised from DynamicLibrary at /opt/conda/conda-bld/pytorch_1702400440653/work/aten/src/ATen/DynamicLibrary.cpp:38 (most recent call first):\n",
      "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x14e34fe44617 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torch/lib/libc10.so)\n",
      "frame #1: <unknown function> + 0xc669fc (0x14e39dd809fc in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\n",
      "frame #2: torchaudio::find_avutil(char const*) + 0x1a (0x14e32dce24ca in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torchaudio/lib/libtorchaudio.so)\n",
      "frame #3: <unknown function> + 0x7f8e (0x14e32dc91f8e in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torchaudio/lib/_torchaudio.so)\n",
      "frame #4: <unknown function> + 0x12847 (0x14e32dc9c847 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/torchaudio/lib/_torchaudio.so)\n",
      "frame #5: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x528187]\n",
      "frame #6: _PyObject_MakeTpCall + 0x27c (0x503a0c in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #7: _PyEval_EvalFrameDefault + 0x6a3 (0x510f33 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #8: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5cb55a]\n",
      "frame #9: PyEval_EvalCode + 0x9f (0x5cac2f in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #10: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5e43d3]\n",
      "frame #11: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x51e1c7]\n",
      "frame #12: _PyEval_EvalFrameDefault + 0x9025 (0x5198b5 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #13: _PyFunction_Vectorcall + 0x173 (0x538733 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #14: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x526b73]\n",
      "frame #15: PyObject_CallMethodObjArgs + 0x11c (0x55600c in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #16: PyImport_ImportModuleLevelObject + 0x757 (0x555b57 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #17: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x56a2d0]\n",
      "frame #18: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x51e1c7]\n",
      "frame #19: _PyEval_EvalFrameDefault + 0x9025 (0x5198b5 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #20: _PyFunction_Vectorcall + 0x173 (0x538733 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #21: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x526b73]\n",
      "frame #22: PyObject_CallMethodObjArgs + 0x11c (0x55600c in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #23: PyImport_ImportModuleLevelObject + 0x971 (0x555d71 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #24: _PyEval_EvalFrameDefault + 0x5f73 (0x516803 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #25: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5cb55a]\n",
      "frame #26: PyEval_EvalCode + 0x9f (0x5cac2f in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #27: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5e43d3]\n",
      "frame #28: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x51e1c7]\n",
      "frame #29: _PyEval_EvalFrameDefault + 0x9025 (0x5198b5 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #30: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5cb55a]\n",
      "frame #31: PyEval_EvalCode + 0x9f (0x5cac2f in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #32: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5e43d3]\n",
      "frame #33: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x51e1c7]\n",
      "frame #34: _PyEval_EvalFrameDefault + 0x9025 (0x5198b5 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #35: _PyFunction_Vectorcall + 0x173 (0x538733 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #36: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x526b73]\n",
      "frame #37: PyObject_CallMethodObjArgs + 0x11c (0x55600c in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #38: PyImport_ImportModuleLevelObject + 0x757 (0x555b57 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #39: _PyEval_EvalFrameDefault + 0x5f73 (0x516803 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #40: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5cb55a]\n",
      "frame #41: PyEval_EvalCode + 0x9f (0x5cac2f in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #42: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5e43d3]\n",
      "frame #43: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x51e1c7]\n",
      "frame #44: _PyEval_EvalFrameDefault + 0x9025 (0x5198b5 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #45: _PyFunction_Vectorcall + 0x173 (0x538733 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #46: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x526b73]\n",
      "frame #47: PyObject_CallMethodObjArgs + 0x11c (0x55600c in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #48: PyImport_ImportModuleLevelObject + 0x757 (0x555b57 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #49: _PyEval_EvalFrameDefault + 0x5f73 (0x516803 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #50: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5cb55a]\n",
      "frame #51: PyEval_EvalCode + 0x9f (0x5cac2f in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #52: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5e43d3]\n",
      "frame #53: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x51e1c7]\n",
      "frame #54: _PyEval_EvalFrameDefault + 0x9025 (0x5198b5 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #55: _PyFunction_Vectorcall + 0x173 (0x538733 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #56: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x526b73]\n",
      "frame #57: PyObject_CallMethodObjArgs + 0x11c (0x55600c in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #58: PyImport_ImportModuleLevelObject + 0x757 (0x555b57 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #59: _PyEval_EvalFrameDefault + 0x5f73 (0x516803 in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #60: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5cb55a]\n",
      "frame #61: PyEval_EvalCode + 0x9f (0x5cac2f in /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python)\n",
      "frame #62: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x5e43d3]\n",
      "frame #63: /gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/bin/python() [0x51e1c7]\n",
      "\n",
      "DEBUG:torchaudio._extension.utils:Attempting to load FFmpeg version 4.\n",
      "DEBUG:torchaudio._extension.utils:Found FFmpeg version 4.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from src.config import config \n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "# import dask\n",
    "# import dask.dataframe as dd\n",
    "# from dask.distributed import Client\n",
    "# from pyngrok import ngrok, conf\n",
    "\n",
    "from src.utils.dataframes import parallelize_dataframe\n",
    "from src.preprocessing.news_parser import infer_author, filter_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1w1-9R-RMNGH"
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqoPHxpNMNGH"
   },
   "outputs": [],
   "source": [
    "## Set Up NGROK-Tunnel\n",
    "conf.get_default().auth_token = \"2WntwErWDt9LxQ2Jfp6C8OxDAMK_7iZVdC1utyZET1PE8cuUg\"\n",
    "\n",
    "public_url = ngrok.connect(8787).public_url\n",
    "print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\".format(public_url, 8787))\n",
    "\n",
    "if 'client' not in globals():\n",
    "  !python -m pip install jupyter-server-proxy\n",
    "  client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CymECzDhh6Mn"
   },
   "source": [
    "### System settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4lfXyeQvfCn"
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCMMsTZyC0BE"
   },
   "source": [
    "### CUDF für hardware acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqFqwisUh6Mn"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
    "# !python rapidsai-csp-utils/colab/pip-install.py\n",
    "# import cudf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRqa0EPy_lpx"
   },
   "source": [
    "## Grobes HTML-Parsing\n",
    "Als erstes müssen wir die HTML-Dokumente zu normalem Text umwandeln, ansonsten sind die Text-Zellen zu groß und führen zu Problemen mit PyArrow/Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4rQifxX6ygR"
   },
   "outputs": [],
   "source": [
    "input_dir = \"data/raw_bzg/\"\n",
    "output_dir = 'data/unraw1_bzg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wy5-WZ4B_A2"
   },
   "outputs": [],
   "source": [
    "# for year in range(2019, 2020):\n",
    "#     print(year)\n",
    "#     df = pd.read_parquet(f\"{input_dir}story_df_raw_{year}.parquet\")\n",
    "#     df = dd.from_pandas(df, npartitions=12)\n",
    "#     df[\"html_body\"] = df[\"html_body\"].apply(body_formatter, meta=pd.Series(dtype=\"str\"))\n",
    "#     df = df.rename(columns={\"html_body\":\"body\"})\n",
    "#     name_function = lambda x: f\"data-{year}-{x}.parquet\"\n",
    "#     df.to_parquet(output_dir, name_function=name_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFnIFQW2Nag7"
   },
   "source": [
    "## Author-Inferenz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHFpynyiq3O4"
   },
   "outputs": [],
   "source": [
    "input_dir = 'data/unraw1_bzg/'\n",
    "output_dir = 'data/unraw2_bzg/'\n",
    "\n",
    "ddf = dd.read_parquet(input_dir+\"*.parquet\")\n",
    "ddf = ddf.repartition(npartitions=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ylwarwpXLegE"
   },
   "outputs": [],
   "source": [
    "# Remove rows for which noo stock ticker is recorded\n",
    "ddf = ddf[ddf.stocks != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7OPUatcMS7C"
   },
   "outputs": [],
   "source": [
    "# Convert `channels`  datatype from string to list\n",
    "ddf[\"channels\"] = ddf[\"channels\"].progress_apply(eval, meta=pd.Series(dtype='object'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eu1EhTqrVpBG"
   },
   "source": [
    "Untersuche als nächstes die Behauptung, dass **PRNewswire** und **Businesswire** den gesamten Markt für Pressemeldungen in den USA kontrollieren. Wenn dem so ist, und sie nicht noch weitere, unwichtige Meldungen veröffentlichen, dann können wir einfach die Newsartikel nach diesen Autoren filtern und uns viel Arbeit ersparen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5mO091MfO6e"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dask.config.set(scheduler=\"processes\")\n",
    "ddf[\"inferred_author\"] = None\n",
    "ddf[\"inferred_author\"] = ddf.body.progress_apply(infer_author, meta=pd.Series(dtype=\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTcPjnU0VZZu"
   },
   "outputs": [],
   "source": [
    "# value_counts for authors\n",
    "auhtor_value_counts = pd.concat([ddf.author.value_counts().head(10), ddf.inferred_author.value_counts().head(10)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNesN9jX1IP0"
   },
   "outputs": [],
   "source": [
    "auhtor_value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKT6tusBp13y"
   },
   "outputs": [],
   "source": [
    "auhtor_value_counts.sum().diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wk6p6woeqJqP"
   },
   "source": [
    "Ungefähr 650k Nachrichten werden ausgelassen, wenn nur die vier Hauptvertreiber von Pressemeldungen berücksichtigt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8X8rHo-CsDCQ"
   },
   "outputs": [],
   "source": [
    "ddf = ddf[~ddf.inferred_author.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHvzym8sFcX_"
   },
   "outputs": [],
   "source": [
    "ddf[\"inferred_author\"] = ddf[\"inferred_author\"].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ufk8_XUjFwdk"
   },
   "outputs": [],
   "source": [
    "ddf[\"channels\"] = ddf.channels.apply(lambda x: str(x), meta=pd.Series(dtype=\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KsEmViTzNvgs"
   },
   "outputs": [],
   "source": [
    "ddf.inferred_author.value_counts().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfNNyD_31sly"
   },
   "outputs": [],
   "source": [
    "ddf.inferred_author.value_counts().sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmMI9DsEhrn2"
   },
   "outputs": [],
   "source": [
    "ddf = ddf.drop(columns=[\"author\"]).rename(columns={\"inferred_author\":\"author\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v04Wy5Y4iudn"
   },
   "outputs": [],
   "source": [
    "name_function = lambda x: f\"data-{x}.parquet\"\n",
    "ddf.to_parquet(output_dir, name_function=name_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CLdnwdyxNFiH"
   },
   "outputs": [],
   "source": [
    "# Contains 100k rows\n",
    "earnings_ddf = ddf[ddf.channels.apply(lambda x: \"Earnings\" in x, meta=pd.Series(dtype=bool))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-zs5SSiVbyp"
   },
   "outputs": [],
   "source": [
    "# value counts for authors of earnings reports (contrast to value counts of all news articles)\n",
    "earnings_ddf.inferred_author.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dVD6j-G9nie"
   },
   "source": [
    "Hier sehen wir, dass es keine einzige Pressemeldung von **Business Wire** gibt, die mit *Earnings* gekennzeichnet sind. Trotzdem gibt es relevante *Earnings* reports von Business Wire. Dies habe ich kurz verifiziert..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jafqZ87tXDKn"
   },
   "source": [
    "Wie viele Nachrichten bleiben, wenn wir auf relevante Ticker filtern? Wir wollen nicht(!) - so ist es momentan - auf die momentane Russell 3k-Zusammensetzung filtern, denn wir wollen auch ungelistete bzw. ehemalige Russell-Aktien beachten.\n",
    "\n",
    "\n",
    "**1. Full-Name-Discovery:**\n",
    "\n",
    "Herausfinden des vollen Namens des Unternehmens für jeden Ticker, damit 1. der Text richtig geparst werden kann und 2. damit wir einen Anhaltspunkt für das Ticker-Grouping haben.\n",
    "\n",
    "\n",
    "**2. Ticker-Filtering:**\n",
    "\n",
    "Alle Ticker herausfiltern, die wir nicht brauchen. Wenn wir aber ein großes Aktienuniversum (mit inzwischen ungelisteten Aktien) benutzen, werden wir fast alle Nachrichten behalten können. Allerdings lassen sich so Fehlerhafte Nachrichten/Ticker etc. herausfiltern.\n",
    "\n",
    "\n",
    "**3. Ticker-Grouping:**\n",
    "\n",
    "Was machen wir, wenn wir mehrerer Aktiengattungen für ein Unternehmen haben? Z.B. Vorzugs- und Stammaktien. Wir können i.A. die Stammaktie nehmen, da diese normalerweise ein höheres Handelsvolumen aufweist. D.h. wir bilden alle Ticker der Benzinga-Nachrichten auf den Ticker der Stammaktie ab.\n",
    "\n",
    "\n",
    "**4. Firmennamen-Nachrichtenkörper-Verifikation:**\n",
    "\n",
    "Da Ticker wiederverwendet werden können bzw. sich verändern können wollen wir sicherstellen, dass der Unternehmensname im Nachrichtenkörper vorkommt. Bzw. generell ist das eine gute Datensäuberungs-Maßnahme. Einerseits verhindern wir,\n",
    "dass später Aktienkurse einer falschen Aktie zugeordnet wird. Andererseits werden dadurch evtl. auch weniger seriöse Nachrichten herausgefiltert, die nicht\n",
    "die Kontaktadresszeile des Unternehmens am Ende besitzen, in dem der vollständige Unternehmensname vorkommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrLjdrfwlmRm"
   },
   "outputs": [],
   "source": [
    "ddf = pd.read_parquet(output_dir)\n",
    "mapper = pd.read_parquet(config.data.benzinga.ticker_name_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70POMUC-PN-n"
   },
   "outputs": [],
   "source": [
    "ddf = ddf[ddf.stocks.isin(mapper.index.to_list())]\n",
    "ddf[\"company_name\"] = ddf.stocks.map(lambda x: mapper.company_names.loc[x], meta=pd.Series(dtype=\"string\"))\n",
    "ddf[\"short_name\"] = ddf.stocks.map(lambda x: mapper.short_name.loc[x], meta=pd.Series(dtype=\"string\"))\n",
    "print(f\"Es verbleiben {ddf.shape[0]} Nachrichten, für die wir den Ticker zu einem Firmennamen aufgelösen konnten.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Xw1JSiI_0JH"
   },
   "source": [
    "### Duplikate Entfernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cEzrJqEN_yuJ"
   },
   "outputs": [],
   "source": [
    "samples_before = ddf.shape[0]\n",
    "ddf = ddf.drop_duplicates()\n",
    "samples_after = ddf.shape[0]\n",
    "print(f\"{samples_before=}, {samples_after=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3F3dOc35YN8k"
   },
   "source": [
    "### Firmennamen-Nachrichtenkörper-Verifikation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_company_name_in_body(df):\n",
    "    return df.apply(lambda x: bool(re.search(x[\"short_name\"],\n",
    "                                             x.title + x[\"body\"].replace(\"( )*\\n( )*\", \" \"),\n",
    "                                             re.IGNORECASE)),\n",
    "                    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mask = parallelize_dataframe(ddf, verify_company_name_in_body, n_cores=os.cpu_count())\n",
    "\n",
    "print(f\"Around {len(ddf.stocks.unique())} stocks before filtering and {len(ddf[mask].stocks.unique())} after\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d46wUvcQTzB8"
   },
   "outputs": [],
   "source": [
    "# If short_name doesn't occurr in the title or in the body, then article seems to be faulty\n",
    "# mask = ddf.apply(lambda x:\n",
    "#                  bool(re.search(x[\"short_name\"],\n",
    "#                                 x.title + x[\"body\"].replace(\"( )*\\n( )*\", \" \"),\n",
    "#                                 re.IGNORECASE)),\n",
    "#                  axis=1,\n",
    "#                  meta=pd.Series(dtype=bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNAFvvVmmWm2"
   },
   "outputs": [],
   "source": [
    "# Filter out faulty news\n",
    "ddf = ddf[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GvhpDVtFh6M6"
   },
   "outputs": [],
   "source": [
    "# TODO omit if time of this module is not large\n",
    "# name_function = lambda x: f\"data-{x}.parquet\"\n",
    "# ddf.to_parquet(cwd+'/data/bzg/latest2/', name_function=name_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bshj1secWQ3P"
   },
   "source": [
    "Bis zu 5k Nachrichten pro Firma, z.B. AT&T, was in 13 Jahren ca. einer Nachricht pro Tag entspricht. Wir wollen nicht das eine Firma mit vielen Junk-Nachrichten das Modell dominiert. Wobei das Modell hoffentlich dann auch die Junk-Nachrichten als solche erkennt und ignoriert. Eher wichtig noch einen `staleness`-Faktor, also wie ähnlich die Nachricht zu Vorhergegangenen ist (i.e. Nachrichten desselben Tages oder derselben Woche).\n",
    "\n",
    "Kategorisieren von Nachrichten (mit Text2Topic, wie Salbrechter?) und eliminieren von Business/Strategic etc.\n",
    "Im Falle von Text2Topic, versuche Estimates des Unternehmens von Dritten zu unterscheiden.\n",
    "\n",
    "Wichtig!!! Unterscheide zwischen LERN-Phase und PRODUKTIONS-Phase.\n",
    "Wir können z.B. CLS-Token in der Produktions-Phase vergleichen, in der Lern-Phase aber noch nicht.\n",
    "\n",
    "Text2Vec -> Business category evtl. entfernen-> Intrastock variance average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make reduced ticker name mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dK5naDT8t1Ap"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11383"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_name_mapper = pd.read_parquet(\"data_shared/ticker_name_mapper.parquet\")\n",
    "\n",
    "ticker_name_mapper_reduced = ddf[[\"stocks\", \"company_name\", \"short_name\"]].drop_duplicates(keep=\"first\")\n",
    "ticker_name_mapper_reduced.to_parquet(\"data_shared/ticker_name_mapper_reduced.parquet\")\n",
    "print(f\"From {ticker_name_mapper.shape[0]} to {ticker_name_mapper_reduced.shape[0]} tickers (reduced)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRABrPVOcaa9"
   },
   "source": [
    "## Parsing News Bodies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8sBkgXJoMNGq"
   },
   "outputs": [],
   "source": [
    "# ddf = pd.read_parquet('data/latest2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qubEijBxMNGt"
   },
   "outputs": [],
   "source": [
    "from src.utils.time import convert_timezone\n",
    "ddf[\"time\"] = ddf[\"time\"].map(lambda x: convert_timezone(pd.to_datetime(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ddf.iloc[:1000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "def filter_df(df):\n",
    "    return df.apply(filter_body, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGlOJPEvFxuP",
    "outputId": "2e7b693a-72c0-46d8-e93c-11f6feb29d09"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 159 ms, sys: 1.21 s, total: 1.37 s\n",
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processed_news: pd.Series = parallelize_dataframe(sample, filter_df, n_cores=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ddf[\"parsed_body\"] = processed_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.to_parquet(config.data.benzinga.cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ihzi516YMNGv"
   },
   "source": [
    "## Filtern von Newstiteln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdbc2yRqMNGv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1DIhhqZMNGv"
   },
   "source": [
    "## Voranstellen von gefilterten Newstiteln an Nachrichtenkörper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFEujkJ-MNGw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaK5pLz4mRHF"
   },
   "source": [
    "## Durschnittlichen Tokenlänge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timedeltas zwischen Nachrichtenmeldungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.read_parquet(config.data.benzinga.cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = ddf.sort_values(\"time\")\n",
    "tmp = ddf[[\"time\", \"stocks\"]]\n",
    "#### Adding timedeltas to the data frame\n",
    "news_timedeltas = tmp.groupby(\"stocks\").transform(lambda x: x.diff())\n",
    "ddf.loc[:, \"timedelta\"] = news_timedeltas.time.fillna(pd.Timedelta(days=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_timedeltas = ddf.timedelta\n",
    "news_timedeltas.iloc[0].components\n",
    "timedelta_in_minutes = news_timedeltas.apply(lambda x: x.total_seconds() / 60)\n",
    "px.histogram(timedelta_in_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VG5rnSiNpWVN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mc6lpRCpfVT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

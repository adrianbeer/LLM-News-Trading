{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Indicators to Price Data\n",
    "Takes the output from `iq_feed_cleaning.ipynb` and for each row, adds indicators. \\\n",
    "This is preferred over calculating the indicators for each timestamp/date, as it saves \n",
    "a lot of computations. \\\n",
    "It does require us to do a look-up, but so does the alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytz\n",
    "eastern = pytz.timezone('US/Eastern')\n",
    "from src.config import config\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "from src.utils.tickers import get_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = get_tickers(config.data.iqfeed.daily.cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta calculatiopn (use intraday?)\n",
    "spy = pd.read_parquet(path=f\"{config.data.iqfeed.daily.cleaned}/SPY_daily.parquet\")\n",
    "prices = pd.read_parquet(path=f\"{config.data.iqfeed.daily.cleaned}/AAPL_daily.parquet\")\n",
    "X = pd.merge(prices, spy, left_index=True, right_index=True, suffixes=(\"_stock\", \"_SPY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"r_stock\"] = X[\"adj_close_stock\"]/X[\"adj_close_stock\"].shift() - 1 \n",
    "X[\"r_SPY\"] = X[\"adj_close_SPY\"]/X[\"adj_close_SPY\"].shift() - 1 \n",
    "returns = X[[\"r_stock\", \"r_SPY\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model\n",
    "# define lists for storing objects\n",
    "coeffs = []\n",
    "cond_vol = []\n",
    "std_resids = []\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for asset in returns.columns:\n",
    "    model = arch_model(returns[asset], mean = 'Constant', vol = 'GARCH', p = 1, o = 0, q = 1).fit(update_freq = 0,\n",
    "                                                                                                    disp = 'off')\n",
    "    coeffs.append(model.params)\n",
    "    cond_vol.append(model.conditional_volatility)\n",
    "    std_resids.append(model.resid / model.conditional_volatility)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the results in df\n",
    "coeffs_df = pd.DataFrame(coeffs, index=returns.columns)\n",
    "cond_vol_df = pd.DataFrame(cond_vol).transpose().set_axis(returns.columns, \n",
    "                                                          axis = 'columns')\n",
    "std_resids_df = pd.DataFrame(std_resids).transpose().set_axis(returns.columns,\n",
    "                                                             axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the constant conditional correlation matrix (CCC) R:\n",
    "\n",
    "R = std_resids_df.transpose().dot(std_resids_df).div(len(std_resids_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate one step ahead forecastof the conditional covariance matrix\n",
    "import numpy as np\n",
    "diag = []\n",
    "D = np.zeros((2, 2))\n",
    "\n",
    "for model in models:\n",
    "    diag.append(model.forecast(horizon = 1).variance.values[-1][0])\n",
    "    \n",
    "diag = np.sqrt(np.array(diag))\n",
    "np.fill_diagonal(D, diag)\n",
    "\n",
    "H = np.matmul(np.matmul(D, R.values), D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = pd.read_csv(\"D:/data/F-F_Research_Data_Factors_daily.CSV\")\n",
    "factors.columns = [\"date\", \"Mkt-RF\", \"SMB\", \"HML\", \"RF\"]\n",
    "factors[\"date\"] = pd.to_datetime(factors.iloc[:, 0], format=\"%Y%m%d\")\n",
    "factors.set_index(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.merge(X.r_stock*100, factors, left_index=True, right_index=True, how=\"inner\").dropna()\n",
    "A.iloc[0, :] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 + A/100).apply(np.cumprod, axis=0).plot(logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors.rolling(252).corr(X.r_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indicators(ticker):\n",
    "    prices = pd.read_parquet(path=f\"{config.data.iqfeed.daily.cleaned}/{ticker}_daily.parquet\")\n",
    "    prices[\"std_252\"] = prices[\"adj_close\"].pct_change().rolling(252, min_periods=252).std()*(252**0.5)\n",
    "    prices[\"dollar_volume\"] = prices[\"adj_volume\"] * (prices[\"adj_close\"] + prices[\"adj_open\"])/2\n",
    "    prices[\"r_intra_(t-1)\"] = (prices[\"adj_close\"] / prices[\"adj_open\"] - 1).shift(periods=1)\n",
    "    prices[\"unadj_open\"] = prices[\"adj_open\"] / prices[\"cum_split_ratio\"]\n",
    "    prices.to_parquet(path=f\"{config.data.iqfeed.daily.cleaned}/{ticker}_daily.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_obj = ThreadPoolExecutor(max_workers=os.cpu_count()-1)\n",
    "ans = pool_obj.map(add_indicators, tickers)\n",
    "result = list(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Indicators to Price Data\n",
    "Takes the output from `iq_feed_cleaning.ipynb` and for each row, adds indicators. \\\n",
    "This is preferred over calculating the indicators for each timestamp/date, as it saves \n",
    "a lot of computations. \\\n",
    "It does require us to do a look-up, but so does the alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Meine Ablage\\NewsTrading\\trading_bot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pytz\n",
    "eastern = pytz.timezone('US/Eastern')\n",
    "from src.config import config\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "from src.utils.tickers import get_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = get_tickers(config.data.iqfeed.daily.cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta calculatiopn (use intraday?)\n",
    "spy = pd.read_parquet(path=f\"{config.data.iqfeed.daily.cleaned}/SPY_daily.parquet\")\n",
    "prices = pd.read_parquet(path=f\"{config.data.iqfeed.daily.cleaned}/AAPL_daily.parquet\")\n",
    "X = pd.merge(prices, spy, left_index=True, right_index=True, suffixes=(\"_stock\", \"_SPY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"r_stock\"] = X[\"adj_close_stock\"]/X[\"adj_close_stock\"].shift() - 1 \n",
    "X[\"r_SPY\"] = X[\"adj_close_SPY\"]/X[\"adj_close_SPY\"].shift() - 1 \n",
    "returns = X[[\"r_stock\", \"r_SPY\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model\n",
    "# define lists for storing objects\n",
    "coeffs = []\n",
    "cond_vol = []\n",
    "std_resids = []\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Meine Ablage\\NewsTrading\\trading_bot\\.venv\\Lib\\site-packages\\arch\\univariate\\base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 0.0003107. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 100 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  warnings.warn(\n",
      "g:\\Meine Ablage\\NewsTrading\\trading_bot\\.venv\\Lib\\site-packages\\arch\\univariate\\base.py:311: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 0.0001177. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 100 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  warnings.warn(\n",
      "g:\\Meine Ablage\\NewsTrading\\trading_bot\\.venv\\Lib\\site-packages\\arch\\univariate\\base.py:766: ConvergenceWarning: The optimizer returned code 4. The message is:\n",
      "Inequality constraints incompatible\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for asset in returns.columns:\n",
    "    model = arch_model(returns[asset], mean = 'Constant', vol = 'GARCH', p = 1, o = 0, q = 1).fit(update_freq = 0,\n",
    "                                                                                                    disp = 'off')\n",
    "    coeffs.append(model.params)\n",
    "    cond_vol.append(model.conditional_volatility)\n",
    "    std_resids.append(model.resid / model.conditional_volatility)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the results in df\n",
    "coeffs_df = pd.DataFrame(coeffs, index=returns.columns)\n",
    "cond_vol_df = pd.DataFrame(cond_vol).transpose().set_axis(returns.columns, \n",
    "                                                          axis = 'columns')\n",
    "std_resids_df = pd.DataFrame(std_resids).transpose().set_axis(returns.columns,\n",
    "                                                             axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the constant conditional correlation matrix (CCC) R:\n",
    "\n",
    "R = std_resids_df.transpose().dot(std_resids_df).div(len(std_resids_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate one step ahead forecastof the conditional covariance matrix\n",
    "import numpy as np\n",
    "diag = []\n",
    "D = np.zeros((2, 2))\n",
    "\n",
    "for model in models:\n",
    "    diag.append(model.forecast(horizon = 1).variance.values[-1][0])\n",
    "    \n",
    "diag = np.sqrt(np.array(diag))\n",
    "np.fill_diagonal(D, diag)\n",
    "\n",
    "H = np.matmul(np.matmul(D, R.values), D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.87133148e-04, 6.89123094e-04],\n",
       "       [6.89123094e-04, 5.86605807e+00]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indicators(ticker):\n",
    "    prices = pd.read_parquet(path=f\"{config.data.iqfeed.daily.cleaned}/{ticker}_daily.parquet\")\n",
    "    prices[\"std_252\"] = prices[\"adj_close\"].pct_change().rolling(252, min_periods=252).std()*(252**0.5)\n",
    "    prices[\"dollar_volume\"] = prices[\"adj_volume\"] * (prices[\"adj_close\"] + prices[\"adj_open\"])/2\n",
    "    prices[\"r_intra_(t-1)\"] = (prices[\"adj_close\"] / prices[\"adj_open\"] - 1).shift(periods=1)\n",
    "    prices[\"unadj_open\"] = prices[\"adj_open\"] / prices[\"cum_split_ratio\"]\n",
    "    prices.to_parquet(path=f\"{config.data.iqfeed.daily.cleaned}/{ticker}_daily.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_obj = ThreadPoolExecutor(max_workers=os.cpu_count()-1)\n",
    "ans = pool_obj.map(add_indicators, tickers)\n",
    "result = list(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

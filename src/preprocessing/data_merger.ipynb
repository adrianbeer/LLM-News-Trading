{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "# import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import IQFeed Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"D:/IQFeedData/FITB_1min.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-14 09:13:00+00:00</td>\n",
       "      <td>14.490</td>\n",
       "      <td>14.49</td>\n",
       "      <td>14.490</td>\n",
       "      <td>14.49</td>\n",
       "      <td>7800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-12-14 09:30:00+00:00</td>\n",
       "      <td>14.510</td>\n",
       "      <td>14.51</td>\n",
       "      <td>14.510</td>\n",
       "      <td>14.51</td>\n",
       "      <td>276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-12-14 09:31:00+00:00</td>\n",
       "      <td>14.480</td>\n",
       "      <td>14.50</td>\n",
       "      <td>14.460</td>\n",
       "      <td>14.48</td>\n",
       "      <td>62801.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-12-14 09:32:00+00:00</td>\n",
       "      <td>14.475</td>\n",
       "      <td>14.54</td>\n",
       "      <td>14.475</td>\n",
       "      <td>14.53</td>\n",
       "      <td>56274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-12-14 09:33:00+00:00</td>\n",
       "      <td>14.530</td>\n",
       "      <td>14.55</td>\n",
       "      <td>14.520</td>\n",
       "      <td>14.55</td>\n",
       "      <td>24412.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time    open   high     low  close   volume\n",
       "0 2010-12-14 09:13:00+00:00  14.490  14.49  14.490  14.49   7800.0\n",
       "1 2010-12-14 09:30:00+00:00  14.510  14.51  14.510  14.51    276.0\n",
       "2 2010-12-14 09:31:00+00:00  14.480  14.50  14.460  14.48  62801.0\n",
       "3 2010-12-14 09:32:00+00:00  14.475  14.54  14.475  14.53  56274.0\n",
       "4 2010-12-14 09:33:00+00:00  14.530  14.55  14.520  14.55  24412.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.read_pickle(\"data/stocks.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_tickers = set(stocks.index.get_level_values(\"ID\").unique())\n",
    "len(stock_tickers)\n",
    "#test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stories = pd.read_pickle(\"data/stories.pkl\")\n",
    "stories = pd.read_pickle(\"data/story_df_raw_2022.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_tickers = set(stories.stocks.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories.time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Channel occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = set()\n",
    "for i in stories.index:\n",
    "    s = pd.Series(json.loads(stories.loc[i].channels)).value_counts()\n",
    "    channels = channels.union(set(s.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=0, index=list(channels), columns=[\"count\"])\n",
    "for i in stories.index:\n",
    "    s = pd.Series(json.loads(stories.loc[i].channels)).value_counts()\n",
    "    df.loc[s.index, \"count\"] += s.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\"count\", ascending=False)\n",
    "df.head(7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert stories.stocks.dtype == stocks.index.dtypes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_targets(df):\n",
    "    required_columns = [\"Close\", \"High\", \"Low\", \"Open\"]\n",
    "    # df.loc[:, \"IntradayReturn\"] = df[\"Close\"]/df[\"Open\"] - 1\n",
    "    df.loc[:, \"CloseToCloseReturn\"] = df[\"Close\"] / df.shift(1)[\"Close\"] - 1\n",
    "    # df.loc[:, \"NextDayReturn\"] = df.shift(-1)[\"Close\"] / df.shift(-1)[\"Open\"] - 1\n",
    "    # df.loc[:, \"CloseToNextOpen\"] = df.shift(-1)[\"Open\"] / df[\"Close\"] - 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.index.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.loc[:, [\"IntradayReturn\", \"NextDayReturn\"]] = np.nan\n",
    "stocks = stocks.swaplevel(0, 1).sort_index(ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = stocks.groupby(\"ID\", as_index=False).apply(add_targets)\n",
    "stocks.index = stocks.index.droplevel(None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import BDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETER \n",
    "typ = \"CloseToCloseReturn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_appropriate_date(timestamp, typ):\n",
    "    if typ == \"CloseToCloseReturn\":\n",
    "        # TODO: Some noise here due to closing auction?\n",
    "        if timestamp.hour < 16: return timestamp.date()\n",
    "        if timestamp.hour >= 16: return timestamp.date() +  BDay(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "get_appropriate_date(stories.NewsTimestamp.iloc[4], typ=\"CloseToCloseReturn\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we use Intraday return then news should only be between 9:40 am and 4pm (us trading hours).\n",
    "# If we use close-to-close return then news for this days CTC should be between yesterday 4pm and today 4pm. \n",
    "stories.loc[:, \"Date\"] = stories.NewsTimestamp.apply(lambda x: get_appropriate_date(x, typ))\n",
    "stories = stories.astype({\"Date\":'datetime64[ns]'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories.rename(columns=dict(stocks=\"ID\"), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stories[[\"Date\", \"NewsTimestamp\", \"ID\", \"body\"]].\\\n",
    "    merge(stocks[\n",
    "        [\n",
    "            # \"IntradayReturn\", \n",
    "            # \"NextDayReturn\", \n",
    "            \"CloseToCloseReturn\"]\n",
    "         ], on=[\"Date\", \"ID\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset.isna().sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_pickle(\"data/dataset.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train-test-split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle(\"data/dataset.pkl\")\n",
    "assert dataset.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "seed = 420\n",
    "### Train-test split -> Auslagern\n",
    "train_idx, test_idx = train_test_split(dataset.index, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter training set for general stock market events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select S&P\n",
    "SnP = stocks.query(\"ID == 'A0AET0'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SnP = add_targets(SnP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1 # Percentage observations classified as too extreme to be used in the training set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"CloseToCloseReturn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_quantile = SnP.loc[:, target_col].quantile(alpha/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_quantile = SnP.loc[:, target_col].quantile(1-alpha/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Upper Quantile: {upper_quantile:.4f}. Lower Quantile: {lower_quantile:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (SnP.loc[:, target_col] >= lower_quantile) & (SnP.loc[:, target_col] <= upper_quantile)\n",
    "\n",
    "# Only select dates where SnP behaved calmly\n",
    "allowed_dates = SnP.loc[mask, :].index.get_level_values(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now trim  training set\n",
    "train_dat = dataset.loc[train_idx, :]\n",
    "adj_train_idx = train_dat.loc[train_dat.Date.isin(allowed_dates)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_train_idx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save train and test indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dataset_train_test_idx.pkl', 'wb') as f:\n",
    "    pickle.dump((adj_train_idx, test_idx), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pandas_market_calendars as mcal\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import plotly.express as px\n",
    "from dotmap import DotMap\n",
    "import yaml\n",
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "import pytz\n",
    "eastern = pytz.timezone('US/Eastern')\n",
    "nyse_cal = mcal.get_calendar('NYSE')\n",
    "\n",
    "\n",
    "config = DotMap(yaml.safe_load(open(\"src/config.yaml\")), _dynamic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Python numpy: cannot convert datetime64[ns] to datetime64[D] (to use with Numba)](https://stackoverflow.com/a/76139900/9079015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_available_candle(prices: pd.DataFrame, \n",
    "                              time: pd.Timestamp) -> pd.Series:\n",
    "    entry_candle_idx = prices.index.get_indexer(target=[time], \n",
    "                                                method=\"bfill\")\n",
    "    entry_candle = prices.take(entry_candle_idx).iloc[0]\n",
    "    return entry_candle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_appropriate_closing_time(time: pd.Timestamp, tz=\"US/Eastern\") -> pd.Timestamp:\n",
    "    if (time.hour < 9) or ((time.hour == 9) and (time.minute < 30)):\n",
    "        return pd.Timestamp(year=time.year, month=time.month, day=time.day, hour=16, minute=1, tz=tz)\n",
    "    else:\n",
    "        valid_days = [x.date() for x in nyse_cal.valid_days(start_date=time.date(), end_date=time.date() + pd.DateOffset(days=10))]\n",
    "        i = 1\n",
    "        while True:\n",
    "            new_time = time + pd.DateOffset(days=i)\n",
    "            if new_time.date() in valid_days:\n",
    "                return pd.Timestamp(year=new_time.year, month=new_time.month, day=new_time.day, hour=16, minute=1, tz=tz)\n",
    "            if i == 7:\n",
    "                return ValueError()\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_appropriate_entry_time(time: pd.Timestamp, tz=\"US/Eastern\") -> pd.Timestamp:\n",
    "    if (time.hour < 9) or ((time.hour == 9) and (time.minute < 30)):\n",
    "        return pd.Timestamp(year=time.year, month=time.month, day=time.day, hour=9, minute=31, tz=tz)\n",
    "    elif (time.hour > 16) or ((time.hour == 16) and (time.minute > 31)):\n",
    "        valid_days = [x.date() for x in nyse_cal.valid_days(start_date=time.date(), end_date=time.date() + pd.DateOffset(days=10))]\n",
    "        i = 1\n",
    "        while True:\n",
    "            new_time = time + pd.DateOffset(days=i)\n",
    "            if new_time.date() in valid_days:\n",
    "                return pd.Timestamp(year=new_time.year, month=new_time.month, day=new_time.day, hour=9, minute=31, tz=tz)\n",
    "            if i == 7:\n",
    "                return ValueError()\n",
    "            i += 1\n",
    "    else:\n",
    "        return time.ceil(\"min\")  + pd.Timedelta(minutes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Preprocess News "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news = dd.read_parquet(path=\"data/processed_news\")\n",
    "news = pd.read_parquet(path=\"data/processed_news/data-0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "news[\"time\"] = news.time.dt.tz_convert(eastern).astype('datetime64[ns, US/Eastern]')\n",
    "\n",
    "# TODO: This can be *improved* by saying that if we are very close to completing the minute e.g. :55, \n",
    "# then we dont take the next candle (T+1), but the candle after the next(T+2).\n",
    "# Watch out, news time is accurate, but candles are right labeled, hence add one minute.\n",
    "news[\"entry_time\"] = news[\"time\"].map(get_appropriate_entry_time)\n",
    "\n",
    "# Necessary to get `us` units, otherwise pandas will always convert back to `ns` for some reason.\n",
    "news[\"nn_exit_time\"] = news[\"time\"].map(get_appropriate_closing_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Preprocess Stock Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: preprocessing is largely done in iq_feed_cleaning... probably can just import and use as is \n",
    "spy: pd.DataFrame = pd.read_parquet(path=f\"{config.data.iqfeed.minute.cleaned}/SPY_1min.parquet\")\n",
    "spy.columns = [x.strip(\"adj_\") for x in spy.columns]\n",
    "spy.columns = [f\"SPY_{x}\" for x in spy.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = [f for f in listdir(config.data.iqfeed.minute.cleaned) if isfile(join(config.data.iqfeed.minute.cleaned, f))]\n",
    "tickers = [x.split(\"_\")[0] for x in onlyfiles]\n",
    "ticker = news.stocks.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices: pd.DataFrame = pd.read_parquet(path=f\"{config.data.iqfeed.minute.cleaned}/{ticker}_1min.parquet\")\n",
    "prices.columns = [x.strip(\"adj_\") for x in prices.columns]\n",
    "prices = prices.sort_values(\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Ticker:Company Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nHandling of multiple tickers for a the same company.\\nIf there is only one price time series available for the company, we simply group together the tickers.\\nHowever in some cases we will have multiple price time series for the same company.\\n\\nE.g. in case of Alphabet (Google) we have two different tickers and two different stock prices for the same\\nunderlying company. Here `GOOG` and `GOOGL` describe two different classes of stock for the same company.\\nIn this case we will try to only look at the main class. \\n\\nWe find this class by choosing the Symbol with the longer stock price history, assuming that the history\\nof it includes(!) the history of the other one completely.\\nIf one time series doesn't include the other we merge the two time series. Ideally based on which time series has more liquidity \\nin a given week or but we will simply decide that the newer time series takes precedence for simplicity. \\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Handling of multiple tickers for a the same company.\n",
    "If there is only one price time series available for the company, we simply group together the tickers.\n",
    "However in some cases we will have multiple price time series for the same company.\n",
    "\n",
    "E.g. in case of Alphabet (Google) we have two different tickers and two different stock prices for the same\n",
    "underlying company. Here `GOOG` and `GOOGL` describe two different classes of stock for the same company.\n",
    "In this case we will try to only look at the main class. \n",
    "\n",
    "We find this class by choosing the Symbol with the longer stock price history, assuming that the history\n",
    "of it includes(!) the history of the other one completely.\n",
    "If one time series doesn't include the other we merge the two time series. Ideally based on which time series has more liquidity \n",
    "in a given week or but we will simply decide that the newer time series takes precedence for simplicity. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_interval(ticker):\n",
    "    try:\n",
    "        price : pd.DataFrame = pd.read_parquet(path=f\"{config.data.iqfeed.minute.cleaned}/{ticker}_1min.parquet\")\n",
    "    except FileNotFoundError:\n",
    "        return (np.NaN, np.NaN)\n",
    "    time_interval = price.index.min(), price.index.max()\n",
    "    return time_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_mapper = pd.read_parquet(\"data_shared/ticker_name_mapper_reduced.parquet\")\n",
    "ticker_mapper[[\"first_date\", \"last_date\"]] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ticker_mapper.index:\n",
    "    ticker_mapper.loc[i, [\"first_date\", \"last_date\"]] = get_time_interval(ticker_mapper.loc[i, \"stocks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_mapper.dropna(inplace=True)\n",
    "ticker_mapper[[\"first_date\", \"last_date\"]] = ticker_mapper[[\"first_date\", \"last_date\"]].apply(pd.to_datetime, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_tickers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # We want only one ticker per company name\n",
    "    df = df.sort_values([\"last_date\", \"first_date\"], ascending=[False, True])\n",
    "    df.loc[df.index[0], \"is_primary_ticker\"] = True\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8133, 6)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_mapper_consolidated = ticker_mapper.copy(deep=True)\n",
    "ticker_mapper_consolidated[\"is_primary_ticker\"] = False\n",
    "ticker_mapper_consolidated = ticker_mapper_consolidated.groupby(\"company_name\", as_index=False).apply(consolidate_tickers)\n",
    "ticker_mapper_consolidated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8071, 6)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_mapper_consolidated[ticker_mapper_consolidated.is_primary_ticker].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_mapper_consolidated.to_parquet(\"data_shared/ticker_name_mapper_consolidated.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = news\n",
    "def get_primary_ticker(ticker, mapper):\n",
    "    company_name = mapper.loc[mapper[\"stocks\"] == ticker, \"company_name\"]\n",
    "    if len(company_name) == 0:\n",
    "        # No matching entry\n",
    "        return None\n",
    "    else:\n",
    "        company_name = company_name.iat[0]\n",
    "    primary_ticker = mapper.loc[(mapper[\"company_name\"] == company_name) & mapper.is_primary_ticker, \"stocks\"].iat[0]\n",
    "    return primary_ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite tickers with consolidated ticker, i.e. the ticker of the time series we use to construct input-output pairs\n",
    "news[\"stocks\"] = news.stocks.map(lambda ticker: get_primary_ticker(ticker, mapper=ticker_mapper_consolidated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190, 11)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 11)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Also merge with  non-adjusted prices. We don't trade penny stocks.\n",
    "# If the price is smaller than 1 when the news come out we don't trade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_news = news[news.stocks == ticker]\n",
    "merged = pd.merge(ticker_news, prices, left_on=\"entry_time\", right_on=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(merged, prices, left_on=\"nn_exit_time\", right_on=\"time\", suffixes=(\"_entry\", \"_exit\"))\n",
    "# We use the O part of the OHLC for intra day candles here for convenienece as well\n",
    "merged[\"r\"] = merged[\"open_exit\"] / merged[\"open_entry\"] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>entry_time</th>\n",
       "      <th>nn_exit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-03 18:05:02-05:00</td>\n",
       "      <td>2010-01-04 09:31:00-05:00</td>\n",
       "      <td>2010-01-04 16:01:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04 11:00:03-05:00</td>\n",
       "      <td>2010-01-04 11:02:00-05:00</td>\n",
       "      <td>2010-01-05 16:01:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-05 09:03:43-05:00</td>\n",
       "      <td>2010-01-05 09:31:00-05:00</td>\n",
       "      <td>2010-01-05 16:01:00-05:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time                entry_time  \\\n",
       "0 2010-01-03 18:05:02-05:00 2010-01-04 09:31:00-05:00   \n",
       "1 2010-01-04 11:00:03-05:00 2010-01-04 11:02:00-05:00   \n",
       "2 2010-01-05 09:03:43-05:00 2010-01-05 09:31:00-05:00   \n",
       "\n",
       "               nn_exit_time  \n",
       "0 2010-01-04 16:01:00-05:00  \n",
       "1 2010-01-05 16:01:00-05:00  \n",
       "2 2010-01-05 16:01:00-05:00  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[[\"time\", \"entry_time\", \"nn_exit_time\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideally we do this for every stock first and then we come back with the complete dataframe... (depends on if it fits in memory)\n",
    "# Merge news and stock prices with spy prices\n",
    "# merged = pd.merge_asof(merged, spy, left_on=\"entry_time\", right_on=\"time\", direction=\"forward\")\n",
    "merged = pd.merge(merged, spy, left_on=\"entry_time\", right_on=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Don't use intraday as exit here (closing candle) but the actual closing auction...\n",
    "# But for that we need the daily time series, not with minute frequency\n",
    "merged = pd.merge(merged, spy, left_on=\"nn_exit_time\", right_on=\"time\", suffixes=(\"_entry\", \"_exit\"))\n",
    "\n",
    "merged.loc[:, \"r_spy\"] = merged[\"SPY_close_exit\"] / merged[\"SPY_close_entry\"] - 1\n",
    "merged.loc[:, \"r_mkt_adj\"] = merged[\"r_spy\"] - merged[\"r\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>stocks</th>\n",
       "      <th>title</th>\n",
       "      <th>channels</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>company_name</th>\n",
       "      <th>short_name</th>\n",
       "      <th>parsed_body</th>\n",
       "      <th>entry_time</th>\n",
       "      <th>...</th>\n",
       "      <th>SPY_volume_entry</th>\n",
       "      <th>SPY_cum_split_ratio_entry</th>\n",
       "      <th>SPY_open_exit</th>\n",
       "      <th>SPY_high_exit</th>\n",
       "      <th>SPY_low_exit</th>\n",
       "      <th>SPY_close_exit</th>\n",
       "      <th>SPY_volume_exit</th>\n",
       "      <th>SPY_cum_split_ratio_exit</th>\n",
       "      <th>r_spy</th>\n",
       "      <th>r_mkt_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-03 18:05:02-05:00</td>\n",
       "      <td>JBLU</td>\n",
       "      <td>JetBlue to Waive Change Fees and Fare Differen...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NEW YORK, Jan. 3 /PRNewswire-FirstCall/ -- Jet...</td>\n",
       "      <td>PRNewswire</td>\n",
       "      <td>JetBlue Airways Corporation</td>\n",
       "      <td>JetBlue Airways</td>\n",
       "      <td>FirstCall      the company   will waive change...</td>\n",
       "      <td>2010-01-04 09:31:00-05:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.631609e+06</td>\n",
       "      <td>0.768816</td>\n",
       "      <td>87.114580</td>\n",
       "      <td>87.129956</td>\n",
       "      <td>87.076139</td>\n",
       "      <td>87.091515</td>\n",
       "      <td>2.674731e+06</td>\n",
       "      <td>0.768816</td>\n",
       "      <td>0.007740</td>\n",
       "      <td>0.004129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04 11:00:03-05:00</td>\n",
       "      <td>JBLU</td>\n",
       "      <td>Celebrate 2010 with JetBlue Airways' Shake Up ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NEW YORK, Jan. 4 /PRNewswire-FirstCall/ -- To ...</td>\n",
       "      <td>PRNewswire</td>\n",
       "      <td>JetBlue Airways Corporation</td>\n",
       "      <td>JetBlue Airways</td>\n",
       "      <td>FirstCall     To celebrate 2010,  the company ...</td>\n",
       "      <td>2010-01-04 11:02:00-05:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.860301e+05</td>\n",
       "      <td>0.768816</td>\n",
       "      <td>87.360601</td>\n",
       "      <td>87.375977</td>\n",
       "      <td>87.352913</td>\n",
       "      <td>87.368289</td>\n",
       "      <td>9.273268e+05</td>\n",
       "      <td>0.768816</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>-0.047636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-05 09:03:43-05:00</td>\n",
       "      <td>JBLU</td>\n",
       "      <td>JetBlue Expands in San Francisco Today</td>\n",
       "      <td>[]</td>\n",
       "      <td>SAN FRANCISCO, Jan. 5 /PRNewswire-FirstCall/ -...</td>\n",
       "      <td>PRNewswire</td>\n",
       "      <td>JetBlue Airways Corporation</td>\n",
       "      <td>JetBlue Airways</td>\n",
       "      <td>FirstCall      the company   today kicks off a...</td>\n",
       "      <td>2010-01-05 09:31:00-05:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.149897e+06</td>\n",
       "      <td>0.768816</td>\n",
       "      <td>87.360601</td>\n",
       "      <td>87.375977</td>\n",
       "      <td>87.352913</td>\n",
       "      <td>87.368289</td>\n",
       "      <td>9.273268e+05</td>\n",
       "      <td>0.768816</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>-0.058859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time stocks  \\\n",
       "0 2010-01-03 18:05:02-05:00   JBLU   \n",
       "1 2010-01-04 11:00:03-05:00   JBLU   \n",
       "2 2010-01-05 09:03:43-05:00   JBLU   \n",
       "\n",
       "                                               title channels  \\\n",
       "0  JetBlue to Waive Change Fees and Fare Differen...       []   \n",
       "1  Celebrate 2010 with JetBlue Airways' Shake Up ...       []   \n",
       "2             JetBlue Expands in San Francisco Today       []   \n",
       "\n",
       "                                                body      author  \\\n",
       "0  NEW YORK, Jan. 3 /PRNewswire-FirstCall/ -- Jet...  PRNewswire   \n",
       "1  NEW YORK, Jan. 4 /PRNewswire-FirstCall/ -- To ...  PRNewswire   \n",
       "2  SAN FRANCISCO, Jan. 5 /PRNewswire-FirstCall/ -...  PRNewswire   \n",
       "\n",
       "                  company_name       short_name  \\\n",
       "0  JetBlue Airways Corporation  JetBlue Airways   \n",
       "1  JetBlue Airways Corporation  JetBlue Airways   \n",
       "2  JetBlue Airways Corporation  JetBlue Airways   \n",
       "\n",
       "                                         parsed_body  \\\n",
       "0  FirstCall      the company   will waive change...   \n",
       "1  FirstCall     To celebrate 2010,  the company ...   \n",
       "2  FirstCall      the company   today kicks off a...   \n",
       "\n",
       "                 entry_time  ... SPY_volume_entry  SPY_cum_split_ratio_entry  \\\n",
       "0 2010-01-04 09:31:00-05:00  ...     1.631609e+06                   0.768816   \n",
       "1 2010-01-04 11:02:00-05:00  ...     1.860301e+05                   0.768816   \n",
       "2 2010-01-05 09:31:00-05:00  ...     2.149897e+06                   0.768816   \n",
       "\n",
       "   SPY_open_exit  SPY_high_exit  SPY_low_exit  SPY_close_exit  \\\n",
       "0      87.114580      87.129956     87.076139       87.091515   \n",
       "1      87.360601      87.375977     87.352913       87.368289   \n",
       "2      87.360601      87.375977     87.352913       87.368289   \n",
       "\n",
       "   SPY_volume_exit  SPY_cum_split_ratio_exit     r_spy  r_mkt_adj  \n",
       "0     2.674731e+06                  0.768816  0.007740   0.004129  \n",
       "1     9.273268e+05                  0.768816  0.004428  -0.047636  \n",
       "2     9.273268e+05                  0.768816  0.002735  -0.058859  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.loc[:, [\"time\", \"stocks\", \"parsed_body\", \"entry_time\", \"r_mkt_adj\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time           datetime64[ns, US/Eastern]\n",
       "stocks                             object\n",
       "parsed_body                        object\n",
       "entry_time     datetime64[ns, US/Eastern]\n",
       "r_mkt_adj                         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>stocks</th>\n",
       "      <th>parsed_body</th>\n",
       "      <th>entry_time</th>\n",
       "      <th>r_mkt_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-03 18:05:02-05:00</td>\n",
       "      <td>JBLU</td>\n",
       "      <td>FirstCall      the company   will waive change...</td>\n",
       "      <td>2010-01-04 09:31:00-05:00</td>\n",
       "      <td>0.004129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04 11:00:03-05:00</td>\n",
       "      <td>JBLU</td>\n",
       "      <td>FirstCall     To celebrate 2010,  the company ...</td>\n",
       "      <td>2010-01-04 11:02:00-05:00</td>\n",
       "      <td>-0.047636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-05 09:03:43-05:00</td>\n",
       "      <td>JBLU</td>\n",
       "      <td>FirstCall      the company   today kicks off a...</td>\n",
       "      <td>2010-01-05 09:31:00-05:00</td>\n",
       "      <td>-0.058859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time stocks  \\\n",
       "0 2010-01-03 18:05:02-05:00   JBLU   \n",
       "1 2010-01-04 11:00:03-05:00   JBLU   \n",
       "2 2010-01-05 09:03:43-05:00   JBLU   \n",
       "\n",
       "                                         parsed_body  \\\n",
       "0  FirstCall      the company   will waive change...   \n",
       "1  FirstCall     To celebrate 2010,  the company ...   \n",
       "2  FirstCall      the company   today kicks off a...   \n",
       "\n",
       "                 entry_time  r_mkt_adj  \n",
       "0 2010-01-04 09:31:00-05:00   0.004129  \n",
       "1 2010-01-04 11:02:00-05:00  -0.047636  \n",
       "2 2010-01-05 09:31:00-05:00  -0.058859  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to Files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns: `time|  stocks  |body  |entry_time  |r_mkt_adj`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting training and test set\n",
    "merged_test = merged.loc[merged.time >= config.model.data.cutoff_date]\n",
    "merged_train = merged.loc[merged.time < config.model.data.cutoff_date]\n",
    "assert merged_test.shape[0] + merged_train.shape[0] == merged.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>stocks</th>\n",
       "      <th>parsed_body</th>\n",
       "      <th>entry_time</th>\n",
       "      <th>r_mkt_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-03 18:05:02-05:00</td>\n",
       "      <td>JBLU</td>\n",
       "      <td>FirstCall      the company   will waive change...</td>\n",
       "      <td>2010-01-04 09:31:00-05:00</td>\n",
       "      <td>0.004129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04 11:00:03-05:00</td>\n",
       "      <td>JBLU</td>\n",
       "      <td>FirstCall     To celebrate 2010,  the company ...</td>\n",
       "      <td>2010-01-04 11:02:00-05:00</td>\n",
       "      <td>-0.047636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-05 09:03:43-05:00</td>\n",
       "      <td>JBLU</td>\n",
       "      <td>FirstCall      the company   today kicks off a...</td>\n",
       "      <td>2010-01-05 09:31:00-05:00</td>\n",
       "      <td>-0.058859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time stocks  \\\n",
       "0 2010-01-03 18:05:02-05:00   JBLU   \n",
       "1 2010-01-04 11:00:03-05:00   JBLU   \n",
       "2 2010-01-05 09:03:43-05:00   JBLU   \n",
       "\n",
       "                                         parsed_body  \\\n",
       "0  FirstCall      the company   will waive change...   \n",
       "1  FirstCall     To celebrate 2010,  the company ...   \n",
       "2  FirstCall      the company   today kicks off a...   \n",
       "\n",
       "                 entry_time  r_mkt_adj  \n",
       "0 2010-01-04 09:31:00-05:00   0.004129  \n",
       "1 2010-01-04 11:02:00-05:00  -0.047636  \n",
       "2 2010-01-05 09:31:00-05:00  -0.058859  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/Data/NN_Training'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.model.data.training\n",
    "config.model.data.testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pandas_market_calendars as mcal\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import plotly.express as px\n",
    "\n",
    "from src.config import TEST_CUTOFF_DATE\n",
    "\n",
    "import pytz\n",
    "eastern = pytz.timezone('US/Eastern')\n",
    "nyse_cal = mcal.get_calendar('NYSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/a/76139900/9079015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minutely Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List off functions for modifying the return\n",
    "raw_iq_feed_data_dir = \"D:/IQFeedData\"\n",
    "\n",
    "# Input-Output-Rows for the neural network training and validation\n",
    "train_output_dir = \"D:/Data/NN_Training\"\n",
    "\n",
    "# Input-Rows for testing\n",
    "test_output_dir = \"D:/Data/NN_Testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_available_candle(prices: pd.DataFrame, \n",
    "                              time: pd.Timestamp) -> pd.Series:\n",
    "    entry_candle_idx = prices.index.get_indexer(target=[time], \n",
    "                                                method=\"bfill\")\n",
    "    entry_candle = prices.take(entry_candle_idx).iloc[0]\n",
    "    return entry_candle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_appropriate_closing_time(time: pd.Timestamp) -> pd.Timestamp:\n",
    "    if (time.hour < 9) or ((time.hour == 9) and (time.minute < 30)):\n",
    "        return pd.Timestamp(year=time.year, month=time.month, day=time.day)\n",
    "    else:\n",
    "        valid_days = [x.date() for x in nyse_cal.valid_days(start_date=time.date(), end_date=time.date() + pd.DateOffset(days=10))]\n",
    "        i = 1\n",
    "        while True:\n",
    "            new_time = time + pd.DateOffset(days=i)\n",
    "            if new_time.date() in valid_days:\n",
    "                return pd.Timestamp(year=new_time.year, month=new_time.month, day=new_time.day)\n",
    "            if i == 7:\n",
    "                return ValueError()\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_iq_feed_prices(prices: pd.DataFrame) -> pd.DataFrame: \n",
    "    if \"time\" in prices.columns:\n",
    "        # Intra-day data\n",
    "        prices.loc[:, \"time\"] = prices.loc[:, \"time\"].dt.tz_localize(None)\n",
    "        prices.loc[:, \"time\"] = prices.loc[:, \"time\"].dt.tz_localize(eastern)\n",
    "        prices.drop_duplicates(keep=\"first\", inplace=True)\n",
    "        prices.dropna(inplace=True)\n",
    "\n",
    "        # Deals with duplicate rows which occurr when not all the digits for volume are \n",
    "        # correctly entered, but only the first 1-3. So keep the largest.\n",
    "        prices = prices.sort_values([\"time\", \"volume\"], ascending=[True, False])\n",
    "        prices = prices.drop_duplicates(subset=[\"time\"], keep=\"first\")\n",
    "\n",
    "        prices.set_index(\"time\", inplace=True)\n",
    "        prices.sort_index(ascending=True, inplace=True)\n",
    "        assert prices.index.is_unique\n",
    "    else:\n",
    "        # Daily data\n",
    "        prices.dropna(inplace=True)\n",
    "        prices[\"date\"] = pd.to_datetime(prices.date)\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Preprocess News "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(path=\"data/unraw2_bzg/data-5.parquet\")\n",
    "df[\"time\"] = df.time.dt.tz_convert(eastern)\n",
    "\n",
    "# TODO: This can be *improved* by saying that if we are very close to completing the minute e.g. :55, \n",
    "# then we dont take the next candle (T+1), but the candle after the next(T+2).\n",
    "df[\"entry_time\"] = df[\"time\"].dt.ceil(\"min\")\n",
    "\n",
    "# Necessary to get `us` units, otherwise pandas will always convert back to `ns` for some reason.\n",
    "df[\"nn_exit_time\"] = df[\"time\"].map(get_appropriate_closing_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Preprocess Stock Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04 04:08:00-05:00</th>\n",
       "      <td>112.25</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04 04:09:00-05:00</th>\n",
       "      <td>112.25</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-04 04:16:00-05:00</th>\n",
       "      <td>112.22</td>\n",
       "      <td>19030.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            close   volume\n",
       "time                                      \n",
       "2010-01-04 04:08:00-05:00  112.25   1000.0\n",
       "2010-01-04 04:09:00-05:00  112.25   1000.0\n",
       "2010-01-04 04:16:00-05:00  112.22  19030.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spy: pd.DataFrame = preprocess_iq_feed_prices(pd.read_parquet(path=f\"{raw_iq_feed_data_dir}/SPY_1min.parquet\", \n",
    "                                                              columns=[\"time\", \"close\", \"volume\"]))\n",
    "spy_daily: pd.DataFrame = preprocess_iq_feed_prices(pd.read_parquet(path=f\"{raw_iq_feed_data_dir}/daily/SPY_daily.parquet\", \n",
    "                                                                    columns=[\"date\", \"close\", \"volume\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = [f for f in listdir(raw_iq_feed_data_dir) if isfile(join(raw_iq_feed_data_dir, f))]\n",
    "tickers = [x.split(\"_\")[0] for x in onlyfiles]\n",
    "ticker = \"AAPL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices: pd.DataFrame = preprocess_iq_feed_prices(pd.read_parquet(path=f\"{raw_iq_feed_data_dir}/{ticker}_1min.parquet\", \n",
    "                                                                 columns=[\"time\", \"close\", \"volume\"]))\n",
    "prices_daily: pd.DataFrame = preprocess_iq_feed_prices(pd.read_parquet(path=f\"{raw_iq_feed_data_dir}/daily/{ticker}_daily.parquet\", \n",
    "                                                                       columns=[\"date\", \"close\", \"volume\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_news = df[df.stocks == ticker]\n",
    "merged = pd.merge_asof(ticker_news, prices, left_on=\"entry_time\", right_on=\"time\", direction=\"forward\")\n",
    "merged = pd.merge(merged, prices_daily, left_on=\"nn_exit_time\", right_on=\"date\", suffixes=(\"_entry\", \"_exit\"))\n",
    "merged[\"r\"] = merged[\"close_exit\"] / merged[\"close_entry\"] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "incompatible merge keys [0] dtype('<M8[ns]') and datetime64[us, US/Eastern], must be the same type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m merged \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge_asof(merged, spy, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentry_time\u001b[39m\u001b[38;5;124m\"\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# TODO: Don't use intraday as exit here (closing candle) but the actual closing auction...\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# But for that we need the daily time series, not with minute frequency\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m merged \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_asof\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnn_exit_time\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_spy_entry\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_spy_exit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m merged\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr_spy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m merged[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose_spy_exit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m merged[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose_spy_entry\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     10\u001b[0m merged\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr_mkt_adj\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m merged[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr_spy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m merged[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mg:\\Meine Ablage\\NewsTrading\\trading_bot\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:616\u001b[0m, in \u001b[0;36mmerge_asof\u001b[1;34m(left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_asof\u001b[39m(\n\u001b[0;32m    362\u001b[0m     left: DataFrame \u001b[38;5;241m|\u001b[39m Series,\n\u001b[0;32m    363\u001b[0m     right: DataFrame \u001b[38;5;241m|\u001b[39m Series,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    375\u001b[0m     direction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    376\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m    377\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;124;03m    Perform a merge by key distance.\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;124;03m    4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN\u001b[39;00m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 616\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_AsOfMerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_by\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_by\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masof\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_exact_matches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_exact_matches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mg:\\Meine Ablage\\NewsTrading\\trading_bot\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1898\u001b[0m, in \u001b[0;36m_AsOfMerge.__init__\u001b[1;34m(self, left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, axis, suffixes, copy, fill_method, how, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[0;32m   1895\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_exact_matches \u001b[38;5;241m=\u001b[39m allow_exact_matches\n\u001b[0;32m   1896\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirection \u001b[38;5;241m=\u001b[39m direction\n\u001b[1;32m-> 1898\u001b[0m \u001b[43m_OrderedMerge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1899\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1902\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1907\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1909\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1911\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\Meine Ablage\\NewsTrading\\trading_bot\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1800\u001b[0m, in \u001b[0;36m_OrderedMerge.__init__\u001b[1;34m(self, left, right, on, left_on, right_on, left_index, right_index, axis, suffixes, fill_method, how)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   1786\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1787\u001b[0m     left: DataFrame \u001b[38;5;241m|\u001b[39m Series,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1797\u001b[0m     how: JoinHow \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masof\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1798\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1799\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_method \u001b[38;5;241m=\u001b[39m fill_method\n\u001b[1;32m-> 1800\u001b[0m     \u001b[43m_MergeOperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1801\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1802\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1803\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1805\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1806\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1808\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1809\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1811\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1812\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# factorize sorts\u001b[39;49;00m\n\u001b[0;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\Meine Ablage\\NewsTrading\\trading_bot\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:737\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[0;32m    732\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[0;32m    733\u001b[0m (\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[1;32m--> 737\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[1;32mg:\\Meine Ablage\\NewsTrading\\trading_bot\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2019\u001b[0m, in \u001b[0;36m_AsOfMerge._get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2014\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2015\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2016\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible merge keys [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(lk\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2017\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(rk\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, must be the same type\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2018\u001b[0m             )\n\u001b[1;32m-> 2019\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MergeError(msg)\n\u001b[0;32m   2021\u001b[0m \u001b[38;5;66;03m# validate tolerance; datetime.timedelta or Timedelta if we have a DTI\u001b[39;00m\n\u001b[0;32m   2022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtolerance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mMergeError\u001b[0m: incompatible merge keys [0] dtype('<M8[ns]') and datetime64[us, US/Eastern], must be the same type"
     ]
    }
   ],
   "source": [
    "# Ideally we do this for every stock first and then we come back with the complete dataframe... (depends on if it fits in memory)\n",
    "# Merge news and stock prices with spy prices\n",
    "merged = pd.merge_asof(merged, spy, left_on=\"entry_time\", right_on=\"time\", direction=\"forward\")\n",
    "\n",
    "# TODO: Don't use intraday as exit here (closing candle) but the actual closing auction...\n",
    "# But for that we need the daily time series, not with minute frequency\n",
    "merged = pd.merge_asof(merged, spy_daily, left_on=\"nn_exit_time\", right_on=\"date\", suffixes=(\"_spy_entry\", \"_spy_exit\"))\n",
    "\n",
    "merged.loc[:, \"r_spy\"] = merged[\"close_spy_exit\"] / merged[\"close_spy_entry\"] - 1\n",
    "merged.loc[:, \"r_mkt_adj\"] = merged[\"r_spy\"] = merged[\"r\"]\n",
    "merged = merged.loc[:, [\"time\", \"stocks\", \"body\", \"entry_time\", \"r_mkt_adj\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time            datetime64[us, US/Eastern]\n",
       "stocks                      string[python]\n",
       "author                      string[python]\n",
       "title                       string[python]\n",
       "channels                    string[python]\n",
       "body                        string[python]\n",
       "entry_time      datetime64[us, US/Eastern]\n",
       "nn_exit_time    datetime64[us, US/Eastern]\n",
       "close                              float64\n",
       "volume                             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>stocks</th>\n",
       "      <th>body</th>\n",
       "      <th>entry_time</th>\n",
       "      <th>r_mkt_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-14 10:40:05-04:00</td>\n",
       "      <td>FITB</td>\n",
       "      <td>(via COMTEX News Network)--\n",
       "\n",
       "SmarTrend identif...</td>\n",
       "      <td>2011-04-14 10:41:00-04:00</td>\n",
       "      <td>0.017337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-21 10:38:05-04:00</td>\n",
       "      <td>FITB</td>\n",
       "      <td>(via COMTEX News Network)--\n",
       "\n",
       "SmarTrend identif...</td>\n",
       "      <td>2011-04-21 10:39:00-04:00</td>\n",
       "      <td>-0.000781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-21 11:36:05-04:00</td>\n",
       "      <td>FITB</td>\n",
       "      <td>(via COMTEX News Network)--\n",
       "\n",
       "SmarTrend has det...</td>\n",
       "      <td>2011-04-21 11:37:00-04:00</td>\n",
       "      <td>-0.013740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time stocks  \\\n",
       "0 2011-04-14 10:40:05-04:00   FITB   \n",
       "1 2011-04-21 10:38:05-04:00   FITB   \n",
       "2 2011-04-21 11:36:05-04:00   FITB   \n",
       "\n",
       "                                                body  \\\n",
       "0  (via COMTEX News Network)--\n",
       "\n",
       "SmarTrend identif...   \n",
       "1  (via COMTEX News Network)--\n",
       "\n",
       "SmarTrend identif...   \n",
       "2  (via COMTEX News Network)--\n",
       "\n",
       "SmarTrend has det...   \n",
       "\n",
       "                 entry_time  r_mkt_adj  \n",
       "0 2011-04-14 10:41:00-04:00   0.017337  \n",
       "1 2011-04-21 10:39:00-04:00  -0.000781  \n",
       "2 2011-04-21 11:37:00-04:00  -0.013740  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to Files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns: `time|  stocks  |body  |entry_time  |r_mkt_adj`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting training and test set\n",
    "merged_test = merged.loc[merged.time >= TEST_CUTOFF_DATE]\n",
    "merged_train = merged.loc[merged.time < TEST_CUTOFF_DATE]\n",
    "assert merged_test.shape[0] + merged_train.shape[0] == merged.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_dir\n",
    "test_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-06-29 16:00:00-04:00</th>\n",
       "      <td>23.9400</td>\n",
       "      <td>243648.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 16:00:00-04:00</th>\n",
       "      <td>23.6300</td>\n",
       "      <td>59289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01 16:00:00-04:00</th>\n",
       "      <td>21.9000</td>\n",
       "      <td>27885.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-02 16:00:00-04:00</th>\n",
       "      <td>19.2000</td>\n",
       "      <td>34925.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-06 16:00:00-04:00</th>\n",
       "      <td>15.9800</td>\n",
       "      <td>101401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-11 16:00:00-05:00</th>\n",
       "      <td>239.6238</td>\n",
       "      <td>674959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-12 16:00:00-05:00</th>\n",
       "      <td>236.9300</td>\n",
       "      <td>597481.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-13 16:00:00-05:00</th>\n",
       "      <td>239.2900</td>\n",
       "      <td>619644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-14 16:00:00-05:00</th>\n",
       "      <td>251.1401</td>\n",
       "      <td>729480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-15 16:00:00-05:00</th>\n",
       "      <td>253.3400</td>\n",
       "      <td>805492.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3376 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              close    volume\n",
       "time                                         \n",
       "2010-06-29 16:00:00-04:00   23.9400  243648.0\n",
       "2010-06-30 16:00:00-04:00   23.6300   59289.0\n",
       "2010-07-01 16:00:00-04:00   21.9000   27885.0\n",
       "2010-07-02 16:00:00-04:00   19.2000   34925.0\n",
       "2010-07-06 16:00:00-04:00   15.9800  101401.0\n",
       "...                             ...       ...\n",
       "2023-12-11 16:00:00-05:00  239.6238  674959.0\n",
       "2023-12-12 16:00:00-05:00  236.9300  597481.0\n",
       "2023-12-13 16:00:00-05:00  239.2900  619644.0\n",
       "2023-12-14 16:00:00-05:00  251.1401  729480.0\n",
       "2023-12-15 16:00:00-05:00  253.3400  805492.0\n",
       "\n",
       "[3376 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices[(prices.index.hour == 16) & (prices.index.minute==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

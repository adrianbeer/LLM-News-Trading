{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ccf648-8779-4ea5-a446-1d9bb64fc8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gxfs_work/cau/sunms534/trading_bot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gxfs_work/cau/sunms534/.conda/envs/my_pytorch_env/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /gxfs_work/cau/sunms534/trading_bot/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e7322f7-f042-4817-8ca2-de4843cb8a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from src.config import config\n",
    "\n",
    "bodies = pd.read_parquet(config.data.news.stripped, columns=[\"parsed_body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26bdec46-ca16-4fa8-85ea-07a6b76fad6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "tokenizer.train_from_iterator(bodies.parsed_body.values, \n",
    "                              vocab_size=30000, \n",
    "                              min_frequency=10, \n",
    "                              special_tokens=[\n",
    "                                \"<s>\",\n",
    "                                \"<pad>\",\n",
    "                                \"</s>\",\n",
    "                                \"<unk>\",\n",
    "                                \"<mask>\",\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b145a2a1-d2a8-4780-a6c6-eb6b58690969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/models/newstokenizer/vocab.json',\n",
       " 'data/models/newstokenizer/merges.txt']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save files to disk\n",
    "tokenizer.save_model(\"data/models/newstokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c18baff-3832-4c62-8d08-fc370758ae4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding(num_tokens=20, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n"
     ]
    }
   ],
   "source": [
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"data/models/newstokenizer/vocab.json\",\n",
    "    \"data/models/newstokenizer/merges.txt\",\n",
    ")\n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")\n",
    "tokenizer.enable_truncation(max_length=512)\n",
    "\n",
    "x = tokenizer.encode(\"the company is showing strong profits this second quarter. weak profits last quarter were announced though.\")\n",
    "print(\n",
    "    x\n",
    ")\n",
    "# Encoding(num_tokens=7, ...)\n",
    "# tokens: ['<s>', 'Mi', 'Ġestas', 'ĠJuli', 'en', '.', '</s>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a582c26e-2223-43bb-8352-8f8811123952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 4925,\n",
       " 321,\n",
       " 335,\n",
       " 2486,\n",
       " 760,\n",
       " 2766,\n",
       " 402,\n",
       " 901,\n",
       " 409,\n",
       " 18,\n",
       " 2073,\n",
       " 2766,\n",
       " 694,\n",
       " 409,\n",
       " 639,\n",
       " 1080,\n",
       " 2046,\n",
       " 18,\n",
       " 2]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad02ad98-e1f6-4885-b720-d5fab83fed66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "the\n",
      " company\n",
      " is\n",
      " showing\n",
      " strong\n",
      " profits\n",
      " this\n",
      " second\n",
      " quarter\n",
      ".\n",
      " weak\n",
      " profits\n",
      " last\n",
      " quarter\n",
      " were\n",
      " announced\n",
      " though\n",
      ".\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "for id in x.ids:\n",
    "    print(tokenizer.decode([id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c52e2-26f0-4350-9d2a-bf93519bd695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
